{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce2a5ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b96b4c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CUDA ÏÇ¨Ïö© Í∞ÄÎä•: True\n",
      "üñ•Ô∏è GPU Ïù¥Î¶Ñ: NVIDIA GeForce RTX 3070 Ti Laptop GPU\n",
      "üí° PyTorch Î≤ÑÏ†Ñ: 2.4.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"‚úÖ CUDA ÏÇ¨Ïö© Í∞ÄÎä•:\", torch.cuda.is_available())\n",
    "print(\"üñ•Ô∏è GPU Ïù¥Î¶Ñ:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")\n",
    "print(\"üí° PyTorch Î≤ÑÏ†Ñ:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb198738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device is not available.\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS device is available.\")\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"MPS device is not available.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Î™®Îç∏ÏùÑ MPS Ïû•ÏπòÎ°ú Î≥¥ÎÇº Ïàò ÏûàÏäµÎãàÎã§.\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599b3009",
   "metadata": {},
   "source": [
    "# ÏöúÎ°úÎ•º Ïù¥Ïö©Ìï¥ÏÑú ÌÇ§Ìè¨Ïù∏Ìä∏ Ï∂îÏ∂úÌï¥ ÌååÏùºÎ™Ö,ÌÅ¥ÎûòÏä§,Î∞îÏö¥Îî©Î∞ïÏä§,ÌÇ§Ìè¨Ïù∏Ìä∏ csvÎ°ú Ï†ÄÏû•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4236d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9856_jpg.rf.ea556afa054f1d58a77368e0d6fbe27e.jpg: 640x640 2 persons, 192.6ms\n",
      "Speed: 0.7ms preprocess, 192.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è IMG_9856_jpg.rf.ea556afa054f1d58a77368e0d6fbe27e.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/-7-_JPG_jpg.rf.99ae399f205cb2cae89e9fecc260a512.jpg: 640x640 1 person, 214.1ms\n",
      "Speed: 0.5ms preprocess, 214.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-757-_jpg.rf.25f4dc40ddf12b83fe039c6e0f2af371.jpg: 640x640 1 person, 212.1ms\n",
      "Speed: 0.7ms preprocess, 212.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit39_jpg.rf.63fe5c273225a718143226acc8979db6.jpg: 640x640 1 person, 285.8ms\n",
      "Speed: 0.8ms preprocess, 285.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/back-b-1-1-400x600xc_jpg.rf.40a964ae17226710f7842f01aa0f7a4d.jpg: 640x640 1 person, 170.4ms\n",
      "Speed: 0.5ms preprocess, 170.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è back-b-1-1-400x600xc_jpg.rf.40a964ae17226710f7842f01aa0f7a4d.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-104840_jpg.rf.5d828787bcc309bc464efd6f7eafcc19.jpg: 640x640 1 person, 186.4ms\n",
      "Speed: 0.8ms preprocess, 186.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0024_jpg.rf.c1c907cc907eab42d6d122eca874f72d.jpg: 640x640 1 person, 190.6ms\n",
      "Speed: 0.7ms preprocess, 190.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit33_jpg.rf.0e3a12b8607de8a4396bd2316e983245.jpg: 640x640 1 person, 189.2ms\n",
      "Speed: 0.7ms preprocess, 189.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/13_png.rf.757939f05259ed8cb863e0436baf5cc9.jpg: 640x640 1 person, 215.5ms\n",
      "Speed: 0.7ms preprocess, 215.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 13_png.rf.757939f05259ed8cb863e0436baf5cc9.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-886-_jpg.rf.2ac74a39ddc1bc6da82c76033c0d7322.jpg: 640x640 1 person, 171.7ms\n",
      "Speed: 0.8ms preprocess, 171.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit108_jpg.rf.df5f912cf7a5285a60134e74f6198717.jpg: 640x640 1 person, 182.4ms\n",
      "Speed: 0.6ms preprocess, 182.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting62_jpg.rf.65bcfe113b301d3606b5002dd72f33f4.jpg: 640x640 1 person, 163.2ms\n",
      "Speed: 0.5ms preprocess, 163.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0587_JPG.rf.e0dc3a096983036e5bfda549222a60ee.jpg: 640x640 1 person, 177.1ms\n",
      "Speed: 0.6ms preprocess, 177.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/jpg_jpg.rf.8f79d86fe4521c51d8af5c7a696c656c.jpg: 640x640 1 person, 164.9ms\n",
      "Speed: 0.5ms preprocess, 164.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-616-_jpg.rf.881a9641b9dd851a06468fdea9101d29.jpg: 640x640 1 person, 164.8ms\n",
      "Speed: 0.5ms preprocess, 164.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-847-_jpg.rf.80c3cf5c78b39a6f2450ddb1c282e0aa.jpg: 640x640 1 person, 181.1ms\n",
      "Speed: 0.6ms preprocess, 181.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/good_posture_20241012_174331_png.rf.3f1a7895d7c704f5416fdbb5495c2761.jpg: 640x640 1 person, 164.4ms\n",
      "Speed: 0.6ms preprocess, 164.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-705-_jpg.rf.ebc984e88e29f35b23298f0fd54ff5dd.jpg: 640x640 1 person, 182.1ms\n",
      "Speed: 0.8ms preprocess, 182.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1_jpg.rf.259bf7b1ffd9c7c3ea3f4c02b834cd83.jpg: 640x640 2 persons, 175.9ms\n",
      "Speed: 0.5ms preprocess, 175.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 1_jpg.rf.259bf7b1ffd9c7c3ea3f4c02b834cd83.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-956-_jpg.rf.bbbabd72db4cb24c73ce897b727e294f.jpg: 640x640 1 person, 175.0ms\n",
      "Speed: 0.6ms preprocess, 175.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting2_jpg.rf.935322285b0a7cf040241d7460222532.jpg: 640x640 1 person, 177.6ms\n",
      "Speed: 0.6ms preprocess, 177.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-200-_jpg.rf.e776adc17b23b93d8a5763fad16d9162.jpg: 640x640 1 person, 162.2ms\n",
      "Speed: 0.5ms preprocess, 162.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/44_jpg.rf.ad3f772761147dfdcf26287f1d173027.jpg: 640x640 1 person, 162.6ms\n",
      "Speed: 0.6ms preprocess, 162.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/-1-_JPG_jpg.rf.190ebc51ac0c589528ec269ddee22727.jpg: 640x640 1 person, 162.1ms\n",
      "Speed: 0.6ms preprocess, 162.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0687_JPG.rf.8b5eefbb630f385f9607b71fb6ba6a24.jpg: 640x640 1 person, 162.7ms\n",
      "Speed: 0.6ms preprocess, 162.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0042_jpg.rf.408971626233f0d4fa34d2fd774316a9.jpg: 640x640 1 person, 163.3ms\n",
      "Speed: 0.6ms preprocess, 163.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0507_JPG.rf.48e66c703f067493fdd0cb0d4dd01850.jpg: 640x640 1 person, 162.3ms\n",
      "Speed: 0.5ms preprocess, 162.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-459-_jpg.rf.e799f9f56056a53f6a334eca4910596e.jpg: 640x640 1 person, 162.8ms\n",
      "Speed: 0.5ms preprocess, 162.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/ilana-lahav-rqvu_S-lTMs-unsplash_jpg.rf.c3ffaaaee3b4507b1542e93421724b42.jpg: 640x640 3 persons, 183.2ms\n",
      "Speed: 0.6ms preprocess, 183.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe50_jpg.rf.4ad377682e1981c324890be93d84f9ea.jpg: 640x640 1 person, 166.7ms\n",
      "Speed: 0.7ms preprocess, 166.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0015_jpg.rf.ccc17a3e1af19ee5767db74895b236fc.jpg: 640x640 1 person, 163.2ms\n",
      "Speed: 0.6ms preprocess, 163.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9872_jpg.rf.99c43f74f43cbb93e1893d1355e65495.jpg: 640x640 1 person, 162.2ms\n",
      "Speed: 0.6ms preprocess, 162.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/00021_png_jpg.rf.dcb4ea298f2857a4e2c694f711f12747.jpg: 640x640 1 person, 162.5ms\n",
      "Speed: 0.5ms preprocess, 162.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/LINE_ALBUM_202452_240502_49_jpg.rf.2636d23a26ff2c3d5c3b739707f4992b.jpg: 640x640 2 persons, 160.5ms\n",
      "Speed: 0.6ms preprocess, 160.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-787-_jpg.rf.19f2384e11162f7dba5ae17f250d3c36.jpg: 640x640 1 person, 163.7ms\n",
      "Speed: 0.6ms preprocess, 163.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-804-_jpg.rf.034e1e7c2e9e2130113fd596e4732de7.jpg: 640x640 2 persons, 162.0ms\n",
      "Speed: 0.5ms preprocess, 162.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0639_JPG.rf.8716b4f340c17d8b507f18c2de933007.jpg: 640x640 1 person, 162.3ms\n",
      "Speed: 0.6ms preprocess, 162.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/6_jpg.rf.383e81a521a352634a2e9a1aafb85e79.jpg: 640x640 1 person, 161.6ms\n",
      "Speed: 0.6ms preprocess, 161.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-542-_jpg.rf.f59aa6e6cc360630b987ab7b26ae66d2.jpg: 640x640 1 person, 162.8ms\n",
      "Speed: 0.6ms preprocess, 162.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-81-_jpg.rf.ba1b73251ca0081c9b3339616bb6f80c.jpg: 640x640 1 person, 162.1ms\n",
      "Speed: 0.6ms preprocess, 162.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-602-_jpg.rf.92ac7747150e517b2ca9284b21348c49.jpg: 640x640 1 person, 164.8ms\n",
      "Speed: 0.6ms preprocess, 164.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0526_JPG.rf.06a063df239684e784a032ebbd710139.jpg: 640x640 1 person, 161.5ms\n",
      "Speed: 0.6ms preprocess, 161.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-81-_jpg.rf.f5db745f835591e1af8e6e1cf139dee8.jpg: 640x640 1 person, 160.8ms\n",
      "Speed: 0.7ms preprocess, 160.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe57_jpg.rf.d4fac74473bec6f10f3776f0c5e54720.jpg: 640x640 1 person, 161.4ms\n",
      "Speed: 0.5ms preprocess, 161.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/images-3-_jpg.rf.4fd2c49173a0cc39959a91f705013af4.jpg: 640x640 1 person, 160.4ms\n",
      "Speed: 0.6ms preprocess, 160.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è images-3-_jpg.rf.4fd2c49173a0cc39959a91f705013af4.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/8_jpg.rf.119fbdc35ee8887b0145eb87619637ac.jpg: 640x640 1 person, 162.0ms\n",
      "Speed: 0.6ms preprocess, 162.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0031_jpg.rf.0e0a06ede2b8a419cdbf6d97441fd1d3.jpg: 640x640 2 persons, 164.7ms\n",
      "Speed: 0.7ms preprocess, 164.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-146-_jpg.rf.498ae7b69f1c2cb1cd84fccb906fb11c.jpg: 640x640 4 persons, 162.0ms\n",
      "Speed: 0.6ms preprocess, 162.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0040_jpg.rf.7e4cffd3768e8fc77cc806bfd5428123.jpg: 640x640 3 persons, 161.5ms\n",
      "Speed: 0.6ms preprocess, 161.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/LINE_ALBUM_202452_240502_12_jpg.rf.f391535758e7bd83daaccef835b32c48.jpg: 640x640 1 person, 186.5ms\n",
      "Speed: 0.7ms preprocess, 186.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe31_jpg.rf.07b71e49e0debbc01c2809a013dc16d0.jpg: 640x640 1 person, 187.8ms\n",
      "Speed: 0.6ms preprocess, 187.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0533_JPG.rf.68353e1f1a047d0b8867b9097169e56b.jpg: 640x640 1 person, 187.6ms\n",
      "Speed: 0.6ms preprocess, 187.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-278-_jpg.rf.df24358191262f344a98bfa0df7a4eb3.jpg: 640x640 1 person, 184.4ms\n",
      "Speed: 0.5ms preprocess, 184.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0693_JPG.rf.6d73c3e226128314cff1ddf203a35e52.jpg: 640x640 (no detections), 179.3ms\n",
      "Speed: 0.7ms preprocess, 179.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è IMG_E0693_JPG.rf.6d73c3e226128314cff1ddf203a35e52.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "‚ö†Ô∏è IMG_E0693_JPG.rf.6d73c3e226128314cff1ddf203a35e52.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/img-20-_jpg.rf.2bd25105ab9a1aa51f3b06032637bd38.jpg: 640x640 2 persons, 178.9ms\n",
      "Speed: 0.6ms preprocess, 178.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0505_JPG.rf.22057803cf922770194729870615d223.jpg: 640x640 1 person, 176.4ms\n",
      "Speed: 0.5ms preprocess, 176.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17195253690526876_jpg.rf.ae179755954075bcfbb161472209b129.jpg: 640x640 (no detections), 168.2ms\n",
      "Speed: 0.5ms preprocess, 168.2ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 17195253690526876_jpg.rf.ae179755954075bcfbb161472209b129.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0675_JPG.rf.460d0eed2102b04d56a82744b67878e3.jpg: 640x640 1 person, 162.0ms\n",
      "Speed: 0.7ms preprocess, 162.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/mala-postura-306-_jpg.rf.38be31c0ed3353ada4fc52c8be6d44a8.jpg: 640x640 1 person, 162.5ms\n",
      "Speed: 0.6ms preprocess, 162.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9851_jpg.rf.03c810e1047c41a062a623c8f61ddcbf.jpg: 640x640 1 person, 162.0ms\n",
      "Speed: 0.6ms preprocess, 162.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0581_JPG.rf.2e2932249bdd2a8f0bcd5a55321afc38.jpg: 640x640 1 person, 162.7ms\n",
      "Speed: 0.7ms preprocess, 162.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1000_F_104092966_nL4UGHYw6d8Lqnx9kWFhgKrAysrC5Tgj_jpg.rf.9f9dcbd069d5a18e3f6f099191818787.jpg: 640x640 1 person, 179.6ms\n",
      "Speed: 0.8ms preprocess, 179.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sr-massive-health-dangers-minimize-770x442_jpg.rf.2ee956d752715dace075a6024776a3ea.jpg: 640x640 1 person, 183.0ms\n",
      "Speed: 0.9ms preprocess, 183.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-104833_jpg.rf.83537d3d8f94811499fb23561a7927c5.jpg: 640x640 1 person, 180.9ms\n",
      "Speed: 1.1ms preprocess, 180.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1719526099783659_jpg.rf.6b8999bbf5bf918c8ee951252863b3ea.jpg: 640x640 (no detections), 178.1ms\n",
      "Speed: 0.7ms preprocess, 178.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 1719526099783659_jpg.rf.6b8999bbf5bf918c8ee951252863b3ea.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/images-18-_JPG_jpg.rf.2a1973fc1e9f4e13da6685698b5b46f6.jpg: 640x640 2 persons, 166.8ms\n",
      "Speed: 0.6ms preprocess, 166.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è images-18-_JPG_jpg.rf.2a1973fc1e9f4e13da6685698b5b46f6.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0525_JPG.rf.95581c08313fd1c81c57f2d765bb2310.jpg: 640x640 1 person, 160.5ms\n",
      "Speed: 0.8ms preprocess, 160.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-422-_jpg.rf.a57cf1941b8c906f3b00446dabd73ed1.jpg: 640x640 2 persons, 163.5ms\n",
      "Speed: 0.6ms preprocess, 163.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-488-_jpg.rf.95947ad7eef14eb74a0e4cfa6dc961a5.jpg: 640x640 1 person, 162.0ms\n",
      "Speed: 0.5ms preprocess, 162.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0575_JPG.rf.04a0e6a02bd879daa146d268f7f4bc6f.jpg: 640x640 1 person, 163.4ms\n",
      "Speed: 0.7ms preprocess, 163.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/istockphoto-1133245598-612x612_jpg.rf.56020afaf38b618e7483f32adb1731b6.jpg: 640x640 1 person, 163.6ms\n",
      "Speed: 0.7ms preprocess, 163.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è istockphoto-1133245598-612x612_jpg.rf.56020afaf38b618e7483f32adb1731b6.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/-4-_JPG_jpg.rf.a946055b0ef250b38b08811dbed608aa.jpg: 640x640 1 person, 203.8ms\n",
      "Speed: 0.5ms preprocess, 203.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è -4-_JPG_jpg.rf.a946055b0ef250b38b08811dbed608aa.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0633_JPG.rf.fdbbf06bea87e6dc9a55f26cecef1e5f.jpg: 640x640 1 person, 184.9ms\n",
      "Speed: 0.6ms preprocess, 184.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe48_jpg.rf.2d57fada572dc41c26f4af808a172866.jpg: 640x640 1 person, 193.3ms\n",
      "Speed: 0.5ms preprocess, 193.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9871_jpg.rf.b268533f83394dc55113d029fd9f16b4.jpg: 640x640 1 person, 188.5ms\n",
      "Speed: 0.6ms preprocess, 188.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/00021_png_jpg.rf.e4c760760ff7339778020a84d689555c.jpg: 640x640 1 person, 206.3ms\n",
      "Speed: 0.7ms preprocess, 206.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit85_jpg.rf.cc1085697350db4a83998c7c5fe196b3.jpg: 640x640 1 person, 182.0ms\n",
      "Speed: 0.6ms preprocess, 182.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/42_jpg.rf.3205638ec83b81c727c34364beb76620.jpg: 640x640 1 person, 201.4ms\n",
      "Speed: 0.8ms preprocess, 201.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9853_jpg.rf.d503b12274360c728e6c4af76abadcde.jpg: 640x640 1 person, 167.4ms\n",
      "Speed: 0.6ms preprocess, 167.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0511_JPG.rf.c7b6ed53af061daebcededf97ef46b0f.jpg: 640x640 1 person, 168.7ms\n",
      "Speed: 0.6ms preprocess, 168.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/42_png.rf.c401977fc1d677c068d5ace85cdc2743.jpg: 640x640 1 person, 189.5ms\n",
      "Speed: 0.7ms preprocess, 189.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0523_JPG.rf.586c559c774ca6e72db035387f0d3b7b.jpg: 640x640 1 person, 188.6ms\n",
      "Speed: 0.6ms preprocess, 188.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/image_20241007_214540_jpg.rf.b91e49fe53135a7a107c162099fa04a8.jpg: 640x640 1 person, 182.4ms\n",
      "Speed: 0.7ms preprocess, 182.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0003_jpg.rf.85ea1da3770b979b1b46997de11aa5ab.jpg: 640x640 1 person, 218.1ms\n",
      "Speed: 0.6ms preprocess, 218.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit3_jpg.rf.fb40955d356d8504c6a22591a9c13d62.jpg: 640x640 2 persons, 197.7ms\n",
      "Speed: 0.6ms preprocess, 197.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0110_jpg.rf.b029f21300bbfbb1631f5f241f4951a5.jpg: 640x640 3 persons, 182.2ms\n",
      "Speed: 0.8ms preprocess, 182.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/train04_png.rf.3cce9b5b4b3988b476d22cc9fd8d731b.jpg: 640x640 1 person, 177.9ms\n",
      "Speed: 0.6ms preprocess, 177.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/maxresdefault_jpg.rf.55fb2df8ca13029f66b884cebb513065.jpg: 640x640 1 person, 168.2ms\n",
      "Speed: 0.6ms preprocess, 168.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è maxresdefault_jpg.rf.55fb2df8ca13029f66b884cebb513065.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/mala-postura-322-_jpg.rf.a5404fcfc80ecbbaea5c696c8ef6c9d5.jpg: 640x640 1 person, 162.8ms\n",
      "Speed: 0.5ms preprocess, 162.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/istockphoto-1000312802-612x612_jpg.rf.63514bd79aa910dd9eebc725c50241ef.jpg: 640x640 1 person, 166.0ms\n",
      "Speed: 0.6ms preprocess, 166.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è istockphoto-1000312802-612x612_jpg.rf.63514bd79aa910dd9eebc725c50241ef.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-11-_jpg.rf.42bae1b47434b9011a740e0fb7362f60.jpg: 640x640 4 persons, 177.3ms\n",
      "Speed: 0.6ms preprocess, 177.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-667-_jpg.rf.d90d13fb5e3b42be71ad8c80ca8ee0c3.jpg: 640x640 1 person, 164.9ms\n",
      "Speed: 0.6ms preprocess, 164.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0040_jpg.rf.8376e802c4eb8e1ac846dc801a173d93.jpg: 640x640 3 persons, 174.8ms\n",
      "Speed: 0.6ms preprocess, 174.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0064_jpg.rf.2ae7ab2d9eae0d9a262d62c9ede97bac.jpg: 640x640 2 persons, 195.1ms\n",
      "Speed: 0.6ms preprocess, 195.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9856_jpg.rf.0c4fbe445dd2a57a9bb3e73dbe690752.jpg: 640x640 1 person, 187.0ms\n",
      "Speed: 0.6ms preprocess, 187.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è IMG_9856_jpg.rf.0c4fbe445dd2a57a9bb3e73dbe690752.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/bad_posture_20241021_141725_png.rf.029b8193fba087d495d044645da4f0ad.jpg: 640x640 1 person, 164.1ms\n",
      "Speed: 0.6ms preprocess, 164.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/00045_png_jpg.rf.6f1f17b7ded6bbcf2fdd8df736c68510.jpg: 640x640 1 person, 163.0ms\n",
      "Speed: 0.7ms preprocess, 163.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 00045_png_jpg.rf.6f1f17b7ded6bbcf2fdd8df736c68510.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0002_jpg.rf.b7be8fba0fc2939fc9eb275b3f61daa8.jpg: 640x640 3 persons, 160.0ms\n",
      "Speed: 0.5ms preprocess, 160.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-440-_jpg.rf.71db0cb60bc74b116d53f88104f4d9f7.jpg: 640x640 1 person, 180.1ms\n",
      "Speed: 0.6ms preprocess, 180.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0008_jpg.rf.ea5a3e055a9d838ded9cfa741636d762.jpg: 640x640 1 person, 191.7ms\n",
      "Speed: 0.6ms preprocess, 191.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0042_jpg.rf.63191ba128f6b4529338e408a0c3d738.jpg: 640x640 1 person, 212.5ms\n",
      "Speed: 0.7ms preprocess, 212.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0625_JPG.rf.558518ad5e102cf9d462e423839fef90.jpg: 640x640 1 person, 180.1ms\n",
      "Speed: 0.8ms preprocess, 180.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit102_jpg.rf.7388208ab30c7eacc9506674f3eeb486.jpg: 640x640 5 persons, 180.9ms\n",
      "Speed: 0.5ms preprocess, 180.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-376-_jpg.rf.61375b2ab187fe8ed87143bafb208cf3.jpg: 640x640 1 person, 166.9ms\n",
      "Speed: 0.6ms preprocess, 166.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/istockphoto-187491090-612x612_jpg.rf.3e7352339cebe2c7b39ce898b6e507c2.jpg: 640x640 1 person, 174.1ms\n",
      "Speed: 0.6ms preprocess, 174.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è istockphoto-187491090-612x612_jpg.rf.3e7352339cebe2c7b39ce898b6e507c2.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-357-_jpg.rf.7888db15b3274fcf358de7e7a9f155c1.jpg: 640x640 1 person, 171.6ms\n",
      "Speed: 0.8ms preprocess, 171.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/val03_png_jpg.rf.f1be4c98cbf5c166b9e3a810431a87f0.jpg: 640x640 2 persons, 162.1ms\n",
      "Speed: 0.6ms preprocess, 162.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-280-_jpg.rf.409eed6a2679bc782688c78b200df728.jpg: 640x640 1 person, 164.9ms\n",
      "Speed: 0.5ms preprocess, 164.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Photo_2567-04-06_01-14-29_AM_jpg.rf.95614c959a6bd5d48f07d249c68845f8.jpg: 640x640 1 person, 160.9ms\n",
      "Speed: 0.6ms preprocess, 160.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-76-_jpg.rf.bdc44c0d65d1d48833c35b600d9dcb79.jpg: 640x640 1 person, 162.5ms\n",
      "Speed: 0.6ms preprocess, 162.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-241-_jpg.rf.46cbe5ce8e0dfe77bb0495d2ea42d8fc.jpg: 640x640 1 person, 178.9ms\n",
      "Speed: 0.5ms preprocess, 178.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0699_JPG.rf.260a3c97cc78fb416dd136d1a0588edd.jpg: 640x640 1 person, 168.8ms\n",
      "Speed: 0.7ms preprocess, 168.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/5dc9b425fd85fd145de9153c_girl-sitting-in-chair_jpg.rf.19d29b99fbd574cdecc7ce3a8c001064.jpg: 640x640 1 person, 165.9ms\n",
      "Speed: 0.6ms preprocess, 165.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 5dc9b425fd85fd145de9153c_girl-sitting-in-chair_jpg.rf.19d29b99fbd574cdecc7ce3a8c001064.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-247-_jpg.rf.ce7a0a972f8b86a627cfcf71df9816e8.jpg: 640x640 4 persons, 162.5ms\n",
      "Speed: 0.7ms preprocess, 162.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è Sitting-247-_jpg.rf.ce7a0a972f8b86a627cfcf71df9816e8.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "‚ö†Ô∏è Sitting-247-_jpg.rf.ce7a0a972f8b86a627cfcf71df9816e8.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "‚ö†Ô∏è Sitting-247-_jpg.rf.ce7a0a972f8b86a627cfcf71df9816e8.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "‚ö†Ô∏è Sitting-247-_jpg.rf.ce7a0a972f8b86a627cfcf71df9816e8.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe32_jpg.rf.075455d85d5e5f84de9b1b231223bb46.jpg: 640x640 1 person, 162.5ms\n",
      "Speed: 0.5ms preprocess, 162.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-719-_jpg.rf.5066361ce13ebc4fbb1178c917472d08.jpg: 640x640 1 person, 161.7ms\n",
      "Speed: 0.6ms preprocess, 161.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/train08_png.rf.7dd9e8e898f940e84b162615f39fe9d2.jpg: 640x448 1 person, 127.0ms\n",
      "Speed: 0.4ms preprocess, 127.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 448)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Standing-120-_jpg.rf.a1f2995095d497bc7854b42b1f06ba87.jpg: 640x640 4 persons, 162.3ms\n",
      "Speed: 0.6ms preprocess, 162.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-521-_jpg.rf.a4dc41eb07786f003b6b9d4108fd898e.jpg: 640x640 4 persons, 161.3ms\n",
      "Speed: 0.6ms preprocess, 161.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-981-_jpg.rf.a945d3fb33e14f13e55c07fb29596510.jpg: 640x640 1 person, 161.3ms\n",
      "Speed: 0.5ms preprocess, 161.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-366-_jpg.rf.33dae8ee8d9b033bffb86266ebdf29a3.jpg: 640x640 1 person, 160.5ms\n",
      "Speed: 0.7ms preprocess, 160.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è posture-366-_jpg.rf.33dae8ee8d9b033bffb86266ebdf29a3.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-255-_jpg.rf.b831a06a33fe5e7bde7bd13b28e01124.jpg: 640x640 1 person, 161.3ms\n",
      "Speed: 0.6ms preprocess, 161.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/good_posture_20241021_180549_png.rf.b70176071ecfb27fd90d9774e2058c59.jpg: 640x640 1 person, 163.3ms\n",
      "Speed: 0.6ms preprocess, 163.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/00063_png_jpg.rf.66d100ce5ec6ee9c90f0ef1d814a363c.jpg: 640x640 1 person, 163.0ms\n",
      "Speed: 0.5ms preprocess, 163.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 00063_png_jpg.rf.66d100ce5ec6ee9c90f0ef1d814a363c.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-435-_jpg.rf.5127472f255d5398308883089cb34bbb.jpg: 640x640 1 person, 162.6ms\n",
      "Speed: 0.8ms preprocess, 162.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è posture-435-_jpg.rf.5127472f255d5398308883089cb34bbb.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1_png.rf.f3112ce7fb26ab975ef6c64fe3d14524.jpg: 640x640 1 person, 162.0ms\n",
      "Speed: 0.6ms preprocess, 162.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit14_jpg.rf.e5ed5570cc0ce89653d9933b01803251.jpg: 640x640 1 person, 160.9ms\n",
      "Speed: 0.6ms preprocess, 160.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit99_jpg.rf.5c2c6ba47d0a27e4fedd40cb1f8d7453.jpg: 640x640 1 person, 162.4ms\n",
      "Speed: 0.7ms preprocess, 162.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-776-_jpg.rf.a61bffd50ac4bf1a5dd6957c5b7d4141.jpg: 640x640 1 person, 163.6ms\n",
      "Speed: 0.7ms preprocess, 163.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-580-_jpg.rf.75e728535fd37725238936ca2776211d.jpg: 640x640 1 person, 162.9ms\n",
      "Speed: 0.6ms preprocess, 162.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-792-_jpg.rf.b243fcdc207e35f4935c33592790bb6d.jpg: 640x640 1 person, 174.5ms\n",
      "Speed: 0.6ms preprocess, 174.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/img-35-_jpg.rf.05a5babe51408cf06648e368d943daf2.jpg: 640x640 1 person, 191.2ms\n",
      "Speed: 0.7ms preprocess, 191.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/mala-postura-266-_jpg.rf.4dd2e0cc1efeadc5811af292a4f19a46.jpg: 640x640 1 person, 172.4ms\n",
      "Speed: 0.8ms preprocess, 172.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/12_png.rf.3e9366ad6236e0f5398dcdc52db66c98.jpg: 640x640 1 person, 160.8ms\n",
      "Speed: 0.7ms preprocess, 160.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 12_png.rf.3e9366ad6236e0f5398dcdc52db66c98.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9862_jpg.rf.10f2b7950077847f3363375c97df96f1.jpg: 640x480 1 person, 122.7ms\n",
      "Speed: 0.4ms preprocess, 122.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-104746_jpg.rf.c7f2788b0945ad5fa13dcf7e74a08ef5.jpg: 640x640 1 person, 161.6ms\n",
      "Speed: 0.9ms preprocess, 161.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-552-_jpg.rf.5f5b3b01ef9c34e707fadde8b3824e0b.jpg: 640x640 1 person, 161.8ms\n",
      "Speed: 0.7ms preprocess, 161.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-285-_jpg.rf.fa829c6ea25c4df1d8c9e6b51037eb89.jpg: 640x640 1 person, 162.4ms\n",
      "Speed: 0.7ms preprocess, 162.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/00005_png_jpg.rf.5b50a3adcf6f63809d6613d939e1d60d.jpg: 640x640 1 person, 161.0ms\n",
      "Speed: 0.7ms preprocess, 161.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0125_jpg.rf.eead109bd2ca0b762e84bda512d63db3.jpg: 640x640 2 persons, 178.2ms\n",
      "Speed: 0.7ms preprocess, 178.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0641_JPG.rf.c31e4e4822441039e934f782dfff8020.jpg: 640x640 1 person, 179.7ms\n",
      "Speed: 0.7ms preprocess, 179.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-131-_jpg.rf.15f3173d16960e55193ed554b28966cd.jpg: 640x640 1 person, 179.8ms\n",
      "Speed: 0.6ms preprocess, 179.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-537-_jpg.rf.7cb691c1d162fd07a795ae8f9b357fc1.jpg: 640x640 1 person, 161.6ms\n",
      "Speed: 0.7ms preprocess, 161.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/bad_posture_20241021_141755_png.rf.7d67b074ef78279444fa65c1eef2f035.jpg: 640x640 1 person, 166.4ms\n",
      "Speed: 0.6ms preprocess, 166.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0677_JPG.rf.d37eca91dd6bd7d3e685bff4d3410f5c.jpg: 640x640 1 person, 194.4ms\n",
      "Speed: 0.8ms preprocess, 194.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0616_JPG.rf.947bc3524a031677de94dd60667da28d.jpg: 640x640 1 person, 160.7ms\n",
      "Speed: 0.7ms preprocess, 160.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0045_jpg.rf.c00606dce58634d293a451da9e269347.jpg: 640x640 2 persons, 178.8ms\n",
      "Speed: 0.8ms preprocess, 178.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-978-_jpg.rf.8ddcc622d3fe5a72bf9db373cdf70bd7.jpg: 640x640 1 person, 180.3ms\n",
      "Speed: 0.7ms preprocess, 180.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit50_jpg.rf.7e4b1f19c9ae98f28722116d913816e6.jpg: 640x640 1 person, 175.9ms\n",
      "Speed: 0.7ms preprocess, 175.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit5_jpg.rf.68f76cf0497170a2ae6127833af59194.jpg: 640x640 3 persons, 167.7ms\n",
      "Speed: 0.6ms preprocess, 167.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-732-_jpg.rf.c41bb49f2be93b473ddfdf94f473050b.jpg: 640x640 1 person, 201.7ms\n",
      "Speed: 0.7ms preprocess, 201.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-46-_jpg.rf.bfa22d7d95c40a25876484cf37e9a7a7.jpg: 640x640 1 person, 174.6ms\n",
      "Speed: 0.6ms preprocess, 174.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è posture-46-_jpg.rf.bfa22d7d95c40a25876484cf37e9a7a7.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-294-_jpg.rf.b70efa6cad4a3f0373eb79980066bddc.jpg: 640x640 1 person, 174.8ms\n",
      "Speed: 0.9ms preprocess, 174.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0540_JPG.rf.11c684dc4f9866b67bbedfe21e11b742.jpg: 640x640 1 person, 165.7ms\n",
      "Speed: 0.6ms preprocess, 165.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17195260969006755_jpg.rf.79738d8d53f26edcf35e30d9753e4c5d.jpg: 640x640 (no detections), 167.7ms\n",
      "Speed: 0.6ms preprocess, 167.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 17195260969006755_jpg.rf.79738d8d53f26edcf35e30d9753e4c5d.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-414-_jpg.rf.ce1a00c4ebf189df49b39a73bdff7080.jpg: 640x640 1 person, 167.7ms\n",
      "Speed: 0.8ms preprocess, 167.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit116_jpg.rf.54664339eb35707adf47a9abccf9dee4.jpg: 640x640 1 person, 161.6ms\n",
      "Speed: 0.7ms preprocess, 161.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sr-massive-health-dangers-minimize-770x442_jpg.rf.f330b8b282d5724582f7274dcee98073.jpg: 640x640 1 person, 161.7ms\n",
      "Speed: 0.7ms preprocess, 161.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è sr-massive-health-dangers-minimize-770x442_jpg.rf.f330b8b282d5724582f7274dcee98073.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/00002_png_jpg.rf.cdfda37ff9c98b0c77af175e0bc8746f.jpg: 640x640 2 persons, 194.3ms\n",
      "Speed: 0.6ms preprocess, 194.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/img-28-_jpg.rf.b6e7a3a624ae875604e132e7b3d8afa5.jpg: 640x640 7 persons, 176.9ms\n",
      "Speed: 0.7ms preprocess, 176.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-355-_jpg.rf.110ac0b3e348e1480a9131d93b7cdb43.jpg: 640x640 1 person, 164.0ms\n",
      "Speed: 0.7ms preprocess, 164.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit43_jpg.rf.2c43583b4a80c91ed4a715eca872fb5e.jpg: 640x640 1 person, 167.5ms\n",
      "Speed: 0.5ms preprocess, 167.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/13_jpg.rf.04ea8bbe9618ea7d6aa31b311e7e70ef.jpg: 640x640 1 person, 165.6ms\n",
      "Speed: 0.6ms preprocess, 165.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/11_jpg.rf.d32c7eaa4a1a444026a44fa3cb8de1b3.jpg: 640x640 1 person, 164.2ms\n",
      "Speed: 0.6ms preprocess, 164.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/13_jpg.rf.3cf95ffe98d58cd499820b0c705891e9.jpg: 640x640 1 person, 173.6ms\n",
      "Speed: 0.5ms preprocess, 173.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/7_jpg.rf.db5e276874fa6f23ce3e6ecdc058c829.jpg: 640x640 1 person, 171.8ms\n",
      "Speed: 0.6ms preprocess, 171.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17_jpg.rf.42ad75ea6dacfa1e07595daf5af6a350.jpg: 640x640 1 person, 165.3ms\n",
      "Speed: 0.7ms preprocess, 165.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0706_JPG.rf.5ef0bf9e0ff99858a22bce818bda9b08.jpg: 640x640 1 person, 163.5ms\n",
      "Speed: 0.7ms preprocess, 163.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-105009_jpg.rf.f737a9d6b57ab4a9e6386d24d04521e7.jpg: 640x640 1 person, 184.1ms\n",
      "Speed: 0.6ms preprocess, 184.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-933-_jpg.rf.5b3abd86362e40d5d4f8502c71e13117.jpg: 640x640 4 persons, 167.2ms\n",
      "Speed: 0.6ms preprocess, 167.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-399-_jpg.rf.f520d70a184938d3c5ec13ae63ef7e2f.jpg: 640x640 1 person, 163.4ms\n",
      "Speed: 0.7ms preprocess, 163.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-104444_jpg.rf.e40656246f6711a53757e84ff7db7d7d.jpg: 640x640 1 person, 164.5ms\n",
      "Speed: 0.6ms preprocess, 164.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0670_JPG.rf.b51677ed25427ab2fea0c114e6d7417b.jpg: 640x640 1 person, 163.6ms\n",
      "Speed: 0.6ms preprocess, 163.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-868-_jpg.rf.272ec398a7f53123de6c369ed8b8c5f7.jpg: 640x640 1 person, 166.9ms\n",
      "Speed: 0.5ms preprocess, 166.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0053_jpg.rf.7a2c60d2a78e802c3519cd099e698722.jpg: 640x640 2 persons, 163.6ms\n",
      "Speed: 0.6ms preprocess, 163.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/44_jpg.rf.4ac5447e078f9721f0036e8975ad87a9.jpg: 640x640 1 person, 165.0ms\n",
      "Speed: 0.6ms preprocess, 165.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0658_JPG.rf.c3ebb066c0594a306bbc056e0ae2284f.jpg: 640x640 1 person, 164.9ms\n",
      "Speed: 0.6ms preprocess, 164.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0062_jpg.rf.47fb2413c4f988eff30fb28ecf0e2bb2.jpg: 640x640 1 person, 163.1ms\n",
      "Speed: 0.5ms preprocess, 163.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pc81_jpg.rf.720bc77629ce5d305b47649527a4d4c9.jpg: 640x640 5 persons, 168.3ms\n",
      "Speed: 0.7ms preprocess, 168.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-729-_jpg.rf.a0a03961fefa43bb4b7778cd93d2daf6.jpg: 640x640 1 person, 161.5ms\n",
      "Speed: 0.7ms preprocess, 161.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-461-_jpg.rf.ce8433bf10b2c3a6989f4391d873cffc.jpg: 640x640 1 person, 160.9ms\n",
      "Speed: 0.7ms preprocess, 160.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/istockphoto-186082270-612x612_jpg.rf.085977723c9c9c572aa9e89915afb72a.jpg: 640x640 1 person, 165.0ms\n",
      "Speed: 0.5ms preprocess, 165.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-105116_jpg.rf.b316e36388dda0c9aee72daa99d0731e.jpg: 640x640 1 person, 164.8ms\n",
      "Speed: 0.5ms preprocess, 164.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/33_jpg.rf.92ba7c6ecc4e28e8cfbfcd717d94fb92.jpg: 640x640 1 person, 164.6ms\n",
      "Speed: 0.6ms preprocess, 164.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-104955_jpg.rf.223ed0b1576c35c57c588ae596ad6841.jpg: 640x640 1 person, 184.2ms\n",
      "Speed: 0.6ms preprocess, 184.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/29_jpg.rf.62fd351c46a240b4a9e62e96eb63344d.jpg: 640x640 1 person, 163.2ms\n",
      "Speed: 0.6ms preprocess, 163.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 29_jpg.rf.62fd351c46a240b4a9e62e96eb63344d.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe53_jpg.rf.3ac711a9c9b63249cb625aad101b6ef8.jpg: 640x640 1 person, 161.5ms\n",
      "Speed: 0.7ms preprocess, 161.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/34_jpg.rf.bed213a1885959407ae0ad8eeb4d9f88.jpg: 640x640 (no detections), 163.7ms\n",
      "Speed: 0.6ms preprocess, 163.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 34_jpg.rf.bed213a1885959407ae0ad8eeb4d9f88.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0653_JPG.rf.70a73859dcfb98a6b3d174466acd2c2a.jpg: 640x640 1 person, 163.8ms\n",
      "Speed: 0.5ms preprocess, 163.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/img-22-_jpg.rf.f242d492a7d48c189b3de59f80f67882.jpg: 640x640 2 persons, 163.8ms\n",
      "Speed: 0.6ms preprocess, 163.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-834-_jpg.rf.1cce2417f67a0935b4ae727668c2a197.jpg: 640x640 1 person, 168.5ms\n",
      "Speed: 0.6ms preprocess, 168.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/images-2-_jpg.rf.180f656c5f79eefc1582fc51cae25ab4.jpg: 640x640 1 person, 186.2ms\n",
      "Speed: 0.6ms preprocess, 186.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è images-2-_jpg.rf.180f656c5f79eefc1582fc51cae25ab4.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1000_F_61119969_nTpgMGtPIvtcNa4mq8BcsAB691UcdwoH_jpg.rf.fdbcc7bba1ec5256a75e8f6565a695d7.jpg: 640x640 1 person, 166.0ms\n",
      "Speed: 0.7ms preprocess, 166.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/LINE_ALBUM_202452_240502_2_jpg.rf.41783d04db1d83f0a6ec4101f60a36e1.jpg: 640x640 2 persons, 167.2ms\n",
      "Speed: 0.6ms preprocess, 167.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0697_JPG.rf.fbd317e3d753ce0c8dd91c4c005bc250.jpg: 640x640 1 person, 167.1ms\n",
      "Speed: 0.5ms preprocess, 167.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1000_F_304745333_Sdz6gHj3G2suYZ021uycRm8i4weOGPtZ_jpg.rf.6310723f1faf00427d3cf20305ff6788.jpg: 640x640 1 person, 162.5ms\n",
      "Speed: 0.6ms preprocess, 162.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 1000_F_304745333_Sdz6gHj3G2suYZ021uycRm8i4weOGPtZ_jpg.rf.6310723f1faf00427d3cf20305ff6788.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit129_jpg.rf.8f32fc40196dd884b5cc706b8fd5c8d6.jpg: 640x640 13 persons, 164.3ms\n",
      "Speed: 0.6ms preprocess, 164.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/11_jpg.rf.a521d30d5e9247c1cb9ead9dd0a40331.jpg: 640x640 1 person, 167.4ms\n",
      "Speed: 0.6ms preprocess, 167.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 11_jpg.rf.a521d30d5e9247c1cb9ead9dd0a40331.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0051_jpg.rf.c658ceb69ed56c21b4132bd1416b8d0b.jpg: 640x640 1 person, 166.6ms\n",
      "Speed: 0.6ms preprocess, 166.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9851_jpg.rf.d79911961f0e191828154e60f4b2ef7b.jpg: 640x640 1 person, 181.7ms\n",
      "Speed: 0.7ms preprocess, 181.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è IMG_9851_jpg.rf.d79911961f0e191828154e60f4b2ef7b.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0554_JPG.rf.27b1a49f59081b40e85cbc34ef88b3b8.jpg: 640x640 1 person, 169.5ms\n",
      "Speed: 0.6ms preprocess, 169.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/50_jpg.rf.17aaf205f3535faac376a88947cb9b74.jpg: 640x640 2 persons, 166.2ms\n",
      "Speed: 0.6ms preprocess, 166.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 50_jpg.rf.17aaf205f3535faac376a88947cb9b74.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-63-_jpg.rf.f45366a74bf45367a9f942812be9f840.jpg: 640x640 1 person, 164.3ms\n",
      "Speed: 0.7ms preprocess, 164.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-193-_jpg.rf.0f0bf79397dd78488338d71238a0e4b0.jpg: 640x640 2 persons, 166.1ms\n",
      "Speed: 0.6ms preprocess, 166.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/00062_png_jpg.rf.a9abff9b8a6469984f8895b5bfbdd366.jpg: 640x640 1 person, 167.1ms\n",
      "Speed: 0.6ms preprocess, 167.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-867-_jpg.rf.d3ed357511c23c4abfac53e4f72c62c5.jpg: 640x640 1 person, 161.3ms\n",
      "Speed: 0.6ms preprocess, 161.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1000_F_869557984_ch1PHdp448ipx4mpmsiD1KvEf7ZQ9QmA_jpg.rf.f61110b8eb784dc9d45760eab57106c2.jpg: 640x640 1 person, 166.6ms\n",
      "Speed: 0.7ms preprocess, 166.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/val04_png_jpg.rf.dc6e24501f704cbf19d854c3032ba061.jpg: 640x640 1 person, 168.3ms\n",
      "Speed: 0.6ms preprocess, 168.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1000_F_373687244_dXXtbRVpHZSlG8nkubkAp1IpI6Cw83Lb_jpg.rf.209ce89d9e6e1176a7e559331c7e645c.jpg: 640x640 2 persons, 159.9ms\n",
      "Speed: 0.7ms preprocess, 159.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0065_jpg.rf.adeba5ebf46d7a6702d0319609b6f2cb.jpg: 640x640 3 persons, 169.4ms\n",
      "Speed: 0.6ms preprocess, 169.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/LINE_ALBUM_202452_240502_34_jpg.rf.80fee3c72b7293138337c3cc43da6ead.jpg: 640x640 1 person, 166.7ms\n",
      "Speed: 0.6ms preprocess, 166.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe46_jpg.rf.f9479ac0a7d116719d67c4db3fc6761e.jpg: 640x640 1 person, 161.7ms\n",
      "Speed: 0.7ms preprocess, 161.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/25_jpg.rf.2542c267a379f291a286ed3cbb2c7163.jpg: 640x640 1 person, 161.4ms\n",
      "Speed: 0.7ms preprocess, 161.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-35-_jpg.rf.6d898b1e0ed24c2cd3e2de3fad1d3a19.jpg: 640x640 1 person, 166.5ms\n",
      "Speed: 0.7ms preprocess, 166.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit68_jpg.rf.a5ab4e51ed263fa921dad0b7d73128c0.jpg: 640x640 1 person, 167.9ms\n",
      "Speed: 0.7ms preprocess, 167.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1719525376493811_jpg.rf.66e9464b1e2014d754788fe4d7424575.jpg: 640x640 (no detections), 165.0ms\n",
      "Speed: 0.6ms preprocess, 165.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 1719525376493811_jpg.rf.66e9464b1e2014d754788fe4d7424575.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0102_jpg.rf.74af03d1f3858c7905e4155b88322f57.jpg: 640x640 3 persons, 160.2ms\n",
      "Speed: 0.6ms preprocess, 160.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-513-_jpg.rf.c4f3f2767da0bbfdcb413ab70bf5b7da.jpg: 640x640 4 persons, 162.1ms\n",
      "Speed: 0.7ms preprocess, 162.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-105009_jpg.rf.72c89c0ea419df18798121c01d710865.jpg: 640x640 1 person, 165.6ms\n",
      "Speed: 0.6ms preprocess, 165.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit100_jpg.rf.e193d3e4b4a2d11773f209bf7a75bf8d.jpg: 640x640 2 persons, 189.6ms\n",
      "Speed: 0.6ms preprocess, 189.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-231-_jpg.rf.c4550c6509c526cc4ff2b60975dcc941.jpg: 640x640 1 person, 163.2ms\n",
      "Speed: 0.6ms preprocess, 163.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9870_jpg.rf.e1b449a39f49f7cf7ad7e82c62ff0f2e.jpg: 640x640 2 persons, 168.0ms\n",
      "Speed: 0.6ms preprocess, 168.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0652_JPG.rf.05128b85d617f3493e537162798b035b.jpg: 640x640 1 person, 163.9ms\n",
      "Speed: 1.0ms preprocess, 163.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17195260987257018_jpg.rf.9117a194806d033f0ed119b624b9ec5a.jpg: 640x640 (no detections), 166.4ms\n",
      "Speed: 0.6ms preprocess, 166.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 17195260987257018_jpg.rf.9117a194806d033f0ed119b624b9ec5a.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9853_jpg.rf.b52c7e7f274da7433623121d5be77d1d.jpg: 640x640 1 person, 164.7ms\n",
      "Speed: 0.7ms preprocess, 164.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0687_JPG.rf.392dc742933b97c9fbe7c42d53327b32.jpg: 640x640 1 person, 164.5ms\n",
      "Speed: 0.6ms preprocess, 164.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/62_jpg.rf.b196f8b92fd291604789bca20d212e75.jpg: 640x640 1 person, 167.8ms\n",
      "Speed: 0.7ms preprocess, 167.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-997-_jpg.rf.4d956ee460896bdb8a23dfb2c1f9ab2c.jpg: 640x640 (no detections), 161.3ms\n",
      "Speed: 0.7ms preprocess, 161.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è posture-997-_jpg.rf.4d956ee460896bdb8a23dfb2c1f9ab2c.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-95-_jpg.rf.d9b787fd5e729fbfce5534f12d362c2f.jpg: 640x640 1 person, 161.5ms\n",
      "Speed: 0.8ms preprocess, 161.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/-_JPG_jpg.rf.68ad293668e38c07b6d6df7e14f3463c.jpg: 640x640 1 person, 162.4ms\n",
      "Speed: 0.7ms preprocess, 162.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/20230415100246_jpg.rf.f57e5dcded9eef38c9d54d7ad5bfe01b.jpg: 640x640 1 person, 162.9ms\n",
      "Speed: 0.6ms preprocess, 162.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-156-_jpg.rf.7e8628df93204cf5eb8d80372dd476da.jpg: 640x640 1 person, 166.7ms\n",
      "Speed: 0.6ms preprocess, 166.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è Sitting-156-_jpg.rf.7e8628df93204cf5eb8d80372dd476da.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0701_JPG.rf.5c4f651dcd75f3643b39e03cc3d6eafb.jpg: 640x640 1 person, 163.5ms\n",
      "Speed: 0.7ms preprocess, 163.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0521_JPG.rf.54284e976ff68f94da07a8c32462f605.jpg: 640x640 1 person, 161.6ms\n",
      "Speed: 0.7ms preprocess, 161.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17195260990530465_jpg.rf.3dabbb7a9236bfe5ee7d12c13fa88814.jpg: 640x640 (no detections), 166.5ms\n",
      "Speed: 0.7ms preprocess, 166.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 17195260990530465_jpg.rf.3dabbb7a9236bfe5ee7d12c13fa88814.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0538_JPG.rf.5f6fc78e8b9390ddd8244f5ca172243a.jpg: 640x640 1 person, 164.2ms\n",
      "Speed: 0.6ms preprocess, 164.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-812-_jpg.rf.87abe27145bff22c4fb42ba91d26effe.jpg: 640x640 2 persons, 166.9ms\n",
      "Speed: 0.7ms preprocess, 166.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-223-_jpg.rf.5c22d604f856014cc4270705bd1e6dac.jpg: 640x640 1 person, 163.3ms\n",
      "Speed: 0.7ms preprocess, 163.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-101-_jpg.rf.1af5046a8f1de7f987fd28473f6dad9d.jpg: 640x640 3 persons, 162.9ms\n",
      "Speed: 0.6ms preprocess, 162.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è Sitting-101-_jpg.rf.1af5046a8f1de7f987fd28473f6dad9d.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-514-_jpg.rf.739a0ad302ce1106bb8f46792db35fbd.jpg: 640x640 3 persons, 177.2ms\n",
      "Speed: 0.5ms preprocess, 177.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/bad_posture_20241021_144638_png.rf.69f8de74bf7a731b50682c53c0daa73d.jpg: 640x640 1 person, 167.9ms\n",
      "Speed: 0.7ms preprocess, 167.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-453-_jpg.rf.067e53a2ade82922dbfb6d56a9a8e241.jpg: 640x640 1 person, 167.4ms\n",
      "Speed: 0.6ms preprocess, 167.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0632_JPG.rf.3292e43052a1a07a8d0ec2c7d0090c0d.jpg: 640x640 1 person, 164.2ms\n",
      "Speed: 0.6ms preprocess, 164.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/good_posture_20241012_174139_png.rf.3f16a61d83396c678963b3741b6b9632.jpg: 640x640 1 person, 163.3ms\n",
      "Speed: 0.6ms preprocess, 163.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-230-_jpg.rf.ad87d302aa61ceb5ff75f39633d753a5.jpg: 640x640 1 person, 161.5ms\n",
      "Speed: 0.6ms preprocess, 161.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0572_JPG.rf.8ce384bed36b2df08168103414bdb9c5.jpg: 640x640 1 person, 162.3ms\n",
      "Speed: 0.7ms preprocess, 162.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9854_jpg.rf.8b8cf5a6fae356bc7c67ec88bcf81045.jpg: 640x640 1 person, 162.2ms\n",
      "Speed: 0.7ms preprocess, 162.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Pic-2020-Sep-11-1-26ee7bc6dc178a4de7fa45e964e6bf84_jpg.rf.a4bd76a2ba9f5341b362b165e17da94b.jpg: 640x640 1 person, 164.8ms\n",
      "Speed: 0.7ms preprocess, 164.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è Pic-2020-Sep-11-1-26ee7bc6dc178a4de7fa45e964e6bf84_jpg.rf.a4bd76a2ba9f5341b362b165e17da94b.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0050_jpg.rf.4ae1db896f69b0de90f56e82394bb83e.jpg: 640x640 1 person, 164.7ms\n",
      "Speed: 0.6ms preprocess, 164.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 0050_jpg.rf.4ae1db896f69b0de90f56e82394bb83e.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0576_JPG.rf.ed0db8a16e895315024bc32afbf6a664.jpg: 640x640 1 person, 162.8ms\n",
      "Speed: 0.7ms preprocess, 162.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit6_jpg.rf.1b381a1b271aa6073da03ecd10425374.jpg: 640x640 2 persons, 165.6ms\n",
      "Speed: 0.6ms preprocess, 165.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/34_jpg.rf.95989ade85bc5215f56f58c6c7285422.jpg: 640x640 1 person, 160.5ms\n",
      "Speed: 0.7ms preprocess, 160.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 34_jpg.rf.95989ade85bc5215f56f58c6c7285422.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-347-_jpg.rf.01495dbf2f8fd813c87457d6e99811e8.jpg: 640x640 1 person, 162.7ms\n",
      "Speed: 0.6ms preprocess, 162.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/hao-pan-V3HTrJymLvM-unsplash_jpg.rf.14b7864c2cfd4d8509a13ae75925c71f.jpg: 640x640 1 person, 165.3ms\n",
      "Speed: 0.6ms preprocess, 165.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pc77_jpg.rf.bacba00981c64de3b7a006fe7b820f2a.jpg: 640x640 3 persons, 163.1ms\n",
      "Speed: 0.6ms preprocess, 163.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/images-22-_JPG_jpg.rf.40f329805a05cd6480a6c3ef2eb6de5b.jpg: 640x640 1 person, 160.9ms\n",
      "Speed: 0.6ms preprocess, 160.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-363-_jpg.rf.93fa5b8bd24a463c2a5b3703b79e8645.jpg: 640x640 2 persons, 167.3ms\n",
      "Speed: 0.6ms preprocess, 167.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è posture-363-_jpg.rf.93fa5b8bd24a463c2a5b3703b79e8645.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-71-_jpg.rf.15ebfd5027a347f6879b134d32c80469.jpg: 640x640 1 person, 161.3ms\n",
      "Speed: 0.7ms preprocess, 161.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/24_jpg.rf.f17593dcfe3d56d77b56006772dc68fd.jpg: 640x640 1 person, 161.7ms\n",
      "Speed: 0.5ms preprocess, 161.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-11-_jpg.rf.c23ba1da08e7a9c4da8bc78d2c50b27d.jpg: 640x640 1 person, 188.9ms\n",
      "Speed: 0.7ms preprocess, 188.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/LINE_ALBUM_202452-_1_240502_4_jpg.rf.8d0e3db73f3cb74972b5f958b9a6f81e.jpg: 640x640 1 person, 164.3ms\n",
      "Speed: 0.7ms preprocess, 164.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-969-_jpg.rf.297f52ab5d9c9d577054bdd33eca7413.jpg: 640x640 1 person, 162.1ms\n",
      "Speed: 0.8ms preprocess, 162.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/28_jpg.rf.8d79d99d3059ca36f36995d27c0e1ae1.jpg: 640x640 2 persons, 168.7ms\n",
      "Speed: 0.6ms preprocess, 168.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 28_jpg.rf.8d79d99d3059ca36f36995d27c0e1ae1.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/171952537617202_jpg.rf.84cf115000c40eb5ca0763dc33d946f1.jpg: 640x640 (no detections), 164.4ms\n",
      "Speed: 0.6ms preprocess, 164.4ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 171952537617202_jpg.rf.84cf115000c40eb5ca0763dc33d946f1.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-898-_jpg.rf.1c97235d4baf7cc07eb57a79f50308d8.jpg: 640x640 2 persons, 165.7ms\n",
      "Speed: 0.7ms preprocess, 165.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/bad_posture_20241013_215714_png.rf.d346416c2b2379c81cb3d85ff065fbef.jpg: 640x640 1 person, 161.8ms\n",
      "Speed: 0.6ms preprocess, 161.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è bad_posture_20241013_215714_png.rf.d346416c2b2379c81cb3d85ff065fbef.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0498_JPG.rf.2993589176c6b73eed7648dc1f9abd9e.jpg: 640x640 1 person, 166.8ms\n",
      "Speed: 0.6ms preprocess, 166.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/bad_posture_20241021_142123_png.rf.0baea02940ba74954c52e0180c7e17fe.jpg: 640x640 1 person, 165.4ms\n",
      "Speed: 0.6ms preprocess, 165.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/tu-the-ngoi-cho-nguoi-bi-thoat-vi-dia-dem-1647932325-_jpg.rf.bb0ea93cc277316699f98c5d996d6c84.jpg: 640x640 1 person, 165.6ms\n",
      "Speed: 0.5ms preprocess, 165.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-105228_jpg.rf.f3c5873531d0cf4f7eb7ae9e654a561b.jpg: 640x640 1 person, 167.4ms\n",
      "Speed: 0.6ms preprocess, 167.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-105214_jpg.rf.476eb5ce68a7fc75b14b1712308f762f.jpg: 640x640 1 person, 164.9ms\n",
      "Speed: 0.7ms preprocess, 164.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0651_JPG.rf.557379a0f588803cece27f64c9442eca.jpg: 640x640 1 person, 168.5ms\n",
      "Speed: 0.7ms preprocess, 168.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/20240711_204254_jpg.rf.03ac8403b450f6872ac3b54cc7723a46.jpg: 640x640 1 person, 161.5ms\n",
      "Speed: 0.5ms preprocess, 161.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-225-_jpg.rf.f36373085bc81d138e914506d94fe14c.jpg: 640x640 1 person, 163.2ms\n",
      "Speed: 0.7ms preprocess, 163.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/55_jpg.rf.ad87ef2b321f00e6080fc2899d1ad486.jpg: 640x640 1 person, 163.8ms\n",
      "Speed: 0.7ms preprocess, 163.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0705_JPG.rf.91ff2943cf79d30cf5be981467b8437a.jpg: 640x640 1 person, 203.9ms\n",
      "Speed: 0.7ms preprocess, 203.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/ngoi-khom-phia-truoc_jpg.rf.2a2780ef479c0811d4fa29bd05a5bd6d.jpg: 640x640 1 person, 169.5ms\n",
      "Speed: 0.7ms preprocess, 169.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-32-_jpg.rf.89b000f886696dfee960443d42603a7e.jpg: 640x640 1 person, 169.9ms\n",
      "Speed: 0.6ms preprocess, 169.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-304-_jpg.rf.01d2db049739286c8e1b0d5583904786.jpg: 640x640 3 persons, 174.1ms\n",
      "Speed: 0.6ms preprocess, 174.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-123-_jpg.rf.3a309362cdcd56bf161209a16d9c9a76.jpg: 640x640 2 persons, 173.5ms\n",
      "Speed: 0.6ms preprocess, 173.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è Sitting-123-_jpg.rf.3a309362cdcd56bf161209a16d9c9a76.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "‚ö†Ô∏è Sitting-123-_jpg.rf.3a309362cdcd56bf161209a16d9c9a76.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/bad_posture_20241021_142022_png.rf.5245609045a9d8a6a18f55cff3474e25.jpg: 640x640 1 person, 164.6ms\n",
      "Speed: 0.7ms preprocess, 164.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9852_jpg.rf.dbdc34f7a777d14d6394aadaf3542ba5.jpg: 640x640 1 person, 162.2ms\n",
      "Speed: 0.6ms preprocess, 162.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è IMG_9852_jpg.rf.dbdc34f7a777d14d6394aadaf3542ba5.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/20230415092314_jpg.rf.04631f4de8e3d76f15604558653cd8b2.jpg: 640x640 1 person, 162.8ms\n",
      "Speed: 0.5ms preprocess, 162.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0031_jpg.rf.755610d2065c9b5171b0d363e79cc010.jpg: 640x640 2 persons, 172.5ms\n",
      "Speed: 0.6ms preprocess, 172.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/22_jpg.rf.8a7d12069ba16986a6c475a02bee26ef.jpg: 640x640 (no detections), 179.7ms\n",
      "Speed: 0.7ms preprocess, 179.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 22_jpg.rf.8a7d12069ba16986a6c475a02bee26ef.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-278-_jpg.rf.c7852b16061906dba1dedf8850cf8771.jpg: 640x640 1 person, 170.0ms\n",
      "Speed: 0.6ms preprocess, 170.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è Sitting-278-_jpg.rf.c7852b16061906dba1dedf8850cf8771.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/12_jpg.rf.33618a099a8345e6680b730258d6f68e.jpg: 640x640 1 person, 168.6ms\n",
      "Speed: 0.7ms preprocess, 168.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17195260987257018_jpg.rf.782c5452f77a4a68ae327fe1fe2097f1.jpg: 640x640 (no detections), 169.7ms\n",
      "Speed: 0.7ms preprocess, 169.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 17195260987257018_jpg.rf.782c5452f77a4a68ae327fe1fe2097f1.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9403-1-768x1024_jpg.rf.c917550a741354c9fed916e42d1bd26f.jpg: 640x640 1 person, 171.4ms\n",
      "Speed: 0.6ms preprocess, 171.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è IMG_9403-1-768x1024_jpg.rf.c917550a741354c9fed916e42d1bd26f.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit101_jpg.rf.800340f682fc706b8ba0a4bbfcb0794e.jpg: 640x640 1 person, 171.2ms\n",
      "Speed: 0.6ms preprocess, 171.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-326-_jpg.rf.b01814a160f56f77016408e2da943447.jpg: 640x640 1 person, 168.0ms\n",
      "Speed: 0.6ms preprocess, 168.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0093_jpg.rf.b14ccdcf3e772a407737f97ddb84136c.jpg: 640x640 2 persons, 161.1ms\n",
      "Speed: 0.6ms preprocess, 161.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-206-_jpg.rf.b5393ae1894e7ee64f3ecdc01cb8fd12.jpg: 640x640 1 person, 161.3ms\n",
      "Speed: 0.6ms preprocess, 161.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1000_F_977651933_JSVrahGWKUMqIOldm475W4R5x6Of9YEc_jpg.rf.c21e64f406f3bcc042e4dc2817685e07.jpg: 640x640 1 person, 165.6ms\n",
      "Speed: 0.6ms preprocess, 165.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1719525373749678_jpg.rf.25491b123efa3412fb700709d270decc.jpg: 640x640 1 person, 162.1ms\n",
      "Speed: 0.5ms preprocess, 162.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0617_JPG.rf.8502dc33a92c91d65a2f93c7a84cf67f.jpg: 640x640 1 person, 169.7ms\n",
      "Speed: 0.6ms preprocess, 169.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9856_jpg.rf.d781f62c2ff81bbbd66f95b43949e58e.jpg: 640x480 1 person, 133.4ms\n",
      "Speed: 0.5ms preprocess, 133.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0642_JPG.rf.50d923bbaa5e2e0608ffbdaebb870c9b.jpg: 640x640 1 person, 179.4ms\n",
      "Speed: 0.6ms preprocess, 179.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-473-_jpg.rf.d0cb0e80f5ca72e5fff4966688986f30.jpg: 640x640 1 person, 182.9ms\n",
      "Speed: 0.6ms preprocess, 182.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0703_JPG.rf.5e719976e288f0fd935098c5185b069f.jpg: 640x640 2 persons, 185.9ms\n",
      "Speed: 0.7ms preprocess, 185.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17195260946510482_jpg.rf.9a7a8991b1edec910c078ad90206b32f.jpg: 640x640 (no detections), 176.0ms\n",
      "Speed: 0.6ms preprocess, 176.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 17195260946510482_jpg.rf.9a7a8991b1edec910c078ad90206b32f.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-384-_jpg.rf.613e8c5e9d1a2d8bd7b48f20362238eb.jpg: 640x640 1 person, 178.7ms\n",
      "Speed: 0.7ms preprocess, 178.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-830-_jpg.rf.82bdf83025704706e68eb52638461547.jpg: 640x640 2 persons, 176.2ms\n",
      "Speed: 0.8ms preprocess, 176.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-218-_jpg.rf.36c23ef27439273b497641ccf5202b90.jpg: 640x640 1 person, 177.6ms\n",
      "Speed: 0.9ms preprocess, 177.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è posture-218-_jpg.rf.36c23ef27439273b497641ccf5202b90.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0526_JPG.rf.49c311e61aa6252cbbacb71c2b4cf0b4.jpg: 640x640 1 person, 179.6ms\n",
      "Speed: 0.6ms preprocess, 179.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0545_JPG.rf.55ec356f320b28fcaa1eb4ab0703b126.jpg: 640x640 1 person, 180.6ms\n",
      "Speed: 0.7ms preprocess, 180.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0501_JPG.rf.239b58f9a93f603468b0e34015660bac.jpg: 640x640 1 person, 180.8ms\n",
      "Speed: 0.8ms preprocess, 180.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0063_jpg.rf.7090af48269a73163f102f501d0fe418.jpg: 640x640 4 persons, 198.2ms\n",
      "Speed: 0.7ms preprocess, 198.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/LINE_ALBUM_202452_240502_35_jpg.rf.f98abadefc0b0fb20d1f9d8f1e98ff26.jpg: 640x640 1 person, 173.5ms\n",
      "Speed: 0.6ms preprocess, 173.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/18_jpg.rf.f1f99751ae5a2f38e5529ca021fcc89a.jpg: 640x640 1 person, 170.1ms\n",
      "Speed: 0.6ms preprocess, 170.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/40_jpg.rf.12b221ac28f932e18ef50652294ae587.jpg: 640x640 1 person, 170.2ms\n",
      "Speed: 0.8ms preprocess, 170.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/19_jpg.rf.556db4fbdc41e39616eaff92f9028698.jpg: 640x640 1 person, 175.3ms\n",
      "Speed: 0.7ms preprocess, 175.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17195260961562347_jpg.rf.6948f830c4902980589bd5624504c153.jpg: 640x640 (no detections), 175.0ms\n",
      "Speed: 0.7ms preprocess, 175.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 17195260961562347_jpg.rf.6948f830c4902980589bd5624504c153.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/34_jpg.rf.130389a496cceda15f4286e7962d191f.jpg: 640x640 1 person, 172.4ms\n",
      "Speed: 0.8ms preprocess, 172.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-646-_jpg.rf.eeaa81e6d37f7e8479c6f9950f60ee01.jpg: 640x640 1 person, 174.8ms\n",
      "Speed: 0.7ms preprocess, 174.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-17-_jpg.rf.91f96fd73056362bc453636dab16aa1c.jpg: 640x640 1 person, 189.4ms\n",
      "Speed: 0.9ms preprocess, 189.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/35_jpg.rf.c4f4b0c2667460f8110cf310ff5af5f4.jpg: 640x640 1 person, 174.5ms\n",
      "Speed: 0.6ms preprocess, 174.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-220-_jpg.rf.8382d7f632b37895a3e80d4786f7e1c6.jpg: 640x640 1 person, 173.0ms\n",
      "Speed: 0.7ms preprocess, 173.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit100_jpg.rf.23dac2d0de7fffe5f133d205b438fa15.jpg: 640x640 2 persons, 182.8ms\n",
      "Speed: 0.5ms preprocess, 182.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe45_jpg.rf.6b0f44b07c106fe6c8b86470fddf7abf.jpg: 640x640 1 person, 178.0ms\n",
      "Speed: 0.6ms preprocess, 178.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17_png.rf.b8cb78cc2ff81b3e3d2b9b42d5c13612.jpg: 640x640 1 person, 178.0ms\n",
      "Speed: 1.0ms preprocess, 178.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 17_png.rf.b8cb78cc2ff81b3e3d2b9b42d5c13612.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-943-_jpg.rf.afd41ad99e08ef9f06683fe75ffcb502.jpg: 640x640 1 person, 173.0ms\n",
      "Speed: 0.7ms preprocess, 173.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/postural_jpg.rf.fff0022032b6a5dfe49ae93b67946d83.jpg: 640x640 4 persons, 171.5ms\n",
      "Speed: 0.7ms preprocess, 171.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17195253755200365_jpg.rf.90b5095cb7d639adbc955aab217675b5.jpg: 640x640 (no detections), 169.8ms\n",
      "Speed: 0.7ms preprocess, 169.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 17195253755200365_jpg.rf.90b5095cb7d639adbc955aab217675b5.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-683-_jpg.rf.73ff9cdc06dcd7af3b472fc0d58c5cbc.jpg: 640x640 2 persons, 176.9ms\n",
      "Speed: 0.6ms preprocess, 176.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/image_20241009_224730_jpg.rf.912f10b075b9c2dc3c773d877b9cdd56.jpg: 640x640 1 person, 173.7ms\n",
      "Speed: 0.6ms preprocess, 173.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0633_JPG.rf.785792c8b2b99f9abb996ae8b90d7419.jpg: 640x640 1 person, 171.1ms\n",
      "Speed: 0.6ms preprocess, 171.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe47_jpg.rf.d1b7d698e367260a83f59c15e9db5b90.jpg: 640x640 3 persons, 176.8ms\n",
      "Speed: 0.6ms preprocess, 176.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-977-_jpg.rf.d3e5e8318fb6a9ea81208de80d0ab741.jpg: 640x640 1 person, 173.0ms\n",
      "Speed: 0.7ms preprocess, 173.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit16_jpg.rf.813622a49794736e27073dbc1d4c2ca0.jpg: 640x640 1 person, 168.2ms\n",
      "Speed: 0.6ms preprocess, 168.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pc80_jpg.rf.e764b677d2d7819bec2d3c06e373e5b1.jpg: 640x640 1 person, 169.3ms\n",
      "Speed: 0.6ms preprocess, 169.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è pc80_jpg.rf.e764b677d2d7819bec2d3c06e373e5b1.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-105346_jpg.rf.a93a1a51825019a82d62587d13c76f8a.jpg: 640x640 1 person, 169.8ms\n",
      "Speed: 0.7ms preprocess, 169.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0074_jpg.rf.7d6035bdccd6983867373711df25240d.jpg: 640x640 1 person, 167.0ms\n",
      "Speed: 0.6ms preprocess, 167.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe65_jpg.rf.c41afc7503fff78f835abec87fe4e90f.jpg: 640x640 2 persons, 198.6ms\n",
      "Speed: 0.6ms preprocess, 198.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17195260984684012_jpg.rf.e071e7dd50ab9af8b95653b625d34f89.jpg: 640x640 (no detections), 165.2ms\n",
      "Speed: 0.8ms preprocess, 165.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 17195260984684012_jpg.rf.e071e7dd50ab9af8b95653b625d34f89.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/41_jpg.rf.a3ded46a507bf5ccd1abbb0197a72aa3.jpg: 640x640 1 person, 167.2ms\n",
      "Speed: 0.6ms preprocess, 167.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-364-_jpg.rf.a761e3eacd67ff94ef5fb100411f6f8c.jpg: 640x640 1 person, 177.0ms\n",
      "Speed: 0.6ms preprocess, 177.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-265-_jpg.rf.5bdac94cb3d21e70ab199c912028c483.jpg: 640x640 1 person, 170.8ms\n",
      "Speed: 0.6ms preprocess, 170.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-681-_jpg.rf.e84426a995c331261d911d82723838f1.jpg: 640x640 1 person, 166.4ms\n",
      "Speed: 0.7ms preprocess, 166.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/23_jpg.rf.a58e9819062e6183adf0b7636d0ff14d.jpg: 640x640 1 person, 172.3ms\n",
      "Speed: 0.6ms preprocess, 172.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 23_jpg.rf.a58e9819062e6183adf0b7636d0ff14d.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0028_jpg.rf.07a666f0341585a98b2f5c1fef202510.jpg: 640x640 1 person, 171.4ms\n",
      "Speed: 0.8ms preprocess, 171.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/11_jpg.rf.9b13de86b417b8c4f2e22b29274c1082.jpg: 640x640 1 person, 167.6ms\n",
      "Speed: 0.7ms preprocess, 167.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0628_JPG.rf.949535adb8f6150d27ef484ed88d162c.jpg: 640x640 1 person, 169.5ms\n",
      "Speed: 0.6ms preprocess, 169.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe20_jpg.rf.f5a3c74d5afdab118c8c9a9821da2fbf.jpg: 640x640 1 person, 172.5ms\n",
      "Speed: 0.8ms preprocess, 172.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-104718_jpg.rf.24ca47c5561597bb4274ba336327d6c4.jpg: 640x640 1 person, 169.5ms\n",
      "Speed: 0.6ms preprocess, 169.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/20240711_205406_jpg.rf.f1a167fbd0b9654052dcf216a401b5c0.jpg: 640x640 1 person, 168.2ms\n",
      "Speed: 0.6ms preprocess, 168.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/images-22-_JPG_jpg.rf.81e2f9fdf310fca49c2eb08592de3e2f.jpg: 640x640 1 person, 170.0ms\n",
      "Speed: 0.8ms preprocess, 170.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-148-_jpg.rf.5e06ea3b0a7ea8284adb47f9a3e27b68.jpg: 640x640 1 person, 172.8ms\n",
      "Speed: 0.7ms preprocess, 172.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-288-_jpg.rf.407d9b25efc207734700b4b5d55297a7.jpg: 640x640 1 person, 166.8ms\n",
      "Speed: 0.6ms preprocess, 166.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/13_jpg.rf.2d9ef89661922563c55c086b4b82a7b3.jpg: 640x640 1 person, 164.8ms\n",
      "Speed: 0.7ms preprocess, 164.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-153-_jpg.rf.d7d9fd5bed635f82003fc8c5079686be.jpg: 640x640 1 person, 171.1ms\n",
      "Speed: 0.7ms preprocess, 171.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/bad_posture_20241021_143853_png.rf.5608ee395a30eabee3331fa8781cd396.jpg: 640x640 1 person, 180.2ms\n",
      "Speed: 0.6ms preprocess, 180.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-486-_jpg.rf.62d17aff13bc3afc4eec73f88471aef8.jpg: 640x640 1 person, 196.6ms\n",
      "Speed: 0.7ms preprocess, 196.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-758-_jpg.rf.ae7e044a477eb6d7dd8e9f5c2a4be7f6.jpg: 640x640 1 person, 177.3ms\n",
      "Speed: 0.7ms preprocess, 177.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9854_jpg.rf.9f686caa344d620ad74fa5f0deca096e.jpg: 640x640 1 person, 179.3ms\n",
      "Speed: 0.6ms preprocess, 179.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è IMG_9854_jpg.rf.9f686caa344d620ad74fa5f0deca096e.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1719526099783659_jpg.rf.d98de31e9ad9947e97fb47e378721ff1.jpg: 640x640 (no detections), 176.5ms\n",
      "Speed: 0.7ms preprocess, 176.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 1719526099783659_jpg.rf.d98de31e9ad9947e97fb47e378721ff1.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-797-_jpg.rf.2b96773322679da42836b6e8e9cc45b3.jpg: 640x640 1 person, 175.8ms\n",
      "Speed: 0.7ms preprocess, 175.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-104840_jpg.rf.e5877d800276c48350f1ed5f937bef72.jpg: 640x640 1 person, 178.0ms\n",
      "Speed: 0.6ms preprocess, 178.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/30_jpg.rf.bb539c1db011bea626d0e36bf0148c4c.jpg: 640x640 2 persons, 173.7ms\n",
      "Speed: 0.6ms preprocess, 173.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-293-_jpg.rf.7d2d20a3e758f144c7f3993023d9c2fa.jpg: 640x640 1 person, 176.1ms\n",
      "Speed: 0.7ms preprocess, 176.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è Sitting-293-_jpg.rf.7d2d20a3e758f144c7f3993023d9c2fa.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/LINE_ALBUM_202452_240502_45_jpg.rf.e70caf5b6ec059e272e17ec33b538f5c.jpg: 640x640 1 person, 175.8ms\n",
      "Speed: 0.6ms preprocess, 175.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/00066_png_jpg.rf.413b48754398026a158da2db10cd8dab.jpg: 640x640 1 person, 172.9ms\n",
      "Speed: 0.7ms preprocess, 172.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0050_jpg.rf.3d3effccf11046ff1f4eee89a9985334.jpg: 640x640 1 person, 166.3ms\n",
      "Speed: 0.6ms preprocess, 166.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 0050_jpg.rf.3d3effccf11046ff1f4eee89a9985334.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0089_jpg.rf.3fc2d5567a542d94189984aa00b120db.jpg: 640x640 2 persons, 169.6ms\n",
      "Speed: 0.6ms preprocess, 169.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/8_jpg.rf.f4f8a8919520b92620196b678cbed7cf.jpg: 640x640 1 person, 176.3ms\n",
      "Speed: 0.6ms preprocess, 176.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0689_JPG.rf.d7340e6b34a790f79545c13bdfc74267.jpg: 640x640 1 person, 176.5ms\n",
      "Speed: 1.0ms preprocess, 176.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-14-_jpg.rf.3d72824735535af7958d4865ff7e42aa.jpg: 640x640 1 person, 174.0ms\n",
      "Speed: 0.7ms preprocess, 174.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-558-_jpg.rf.1f3c6508deed53fddd7a6aaf28b37d2d.jpg: 640x640 1 person, 172.8ms\n",
      "Speed: 0.6ms preprocess, 172.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/20230415093801_jpg.rf.2adfbde62031c5c6b0f2795ef8f06c85.jpg: 640x640 1 person, 173.2ms\n",
      "Speed: 0.7ms preprocess, 173.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit14_jpg.rf.f16649c744986378d0c1af49130e0447.jpg: 640x640 1 person, 197.6ms\n",
      "Speed: 0.8ms preprocess, 197.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17_jpg.rf.99168d3bc32a3f4f76b56858945eafbe.jpg: 640x640 1 person, 174.9ms\n",
      "Speed: 0.7ms preprocess, 174.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0037_jpg.rf.ab04618785ee5ed05365d7ad094f15fa.jpg: 640x640 1 person, 174.4ms\n",
      "Speed: 0.7ms preprocess, 174.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-645-_jpg.rf.17b8e02999dbd064f9ea33efb3a62f7b.jpg: 640x640 5 persons, 176.5ms\n",
      "Speed: 0.5ms preprocess, 176.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-811-_jpg.rf.a171cda82ff5ef6336e5bc8274f7d8a6.jpg: 640x640 1 person, 177.5ms\n",
      "Speed: 0.8ms preprocess, 177.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-104725_jpg.rf.c3e549aead1a25e6db3bf5f208047d02.jpg: 640x640 1 person, 178.1ms\n",
      "Speed: 0.7ms preprocess, 178.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-708-_jpg.rf.118d41952386601addd67f1f47c42e21.jpg: 640x640 1 person, 171.7ms\n",
      "Speed: 0.6ms preprocess, 171.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-878-_jpg.rf.886e7ef25e9543ab084778c980b15811.jpg: 640x640 1 person, 175.3ms\n",
      "Speed: 0.9ms preprocess, 175.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-398-_jpg.rf.9715d9dd217c5044ad2291d39485d86f.jpg: 640x640 1 person, 172.5ms\n",
      "Speed: 0.7ms preprocess, 172.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/postural_jpg.rf.21d4b2efd6f5c722d7a5373306e2049a.jpg: 640x640 1 person, 172.0ms\n",
      "Speed: 0.7ms preprocess, 172.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-191-_jpg.rf.2710130eb2e33e236d399d355c84ae83.jpg: 640x640 1 person, 173.3ms\n",
      "Speed: 0.7ms preprocess, 173.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-104812_jpg.rf.fb33dec6c4fd572ea7376f96cb923ee8.jpg: 640x640 1 person, 171.8ms\n",
      "Speed: 0.5ms preprocess, 171.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-78-_jpg.rf.10ab69ef1f703c4703dec2e68c501292.jpg: 640x640 5 persons, 176.0ms\n",
      "Speed: 0.6ms preprocess, 176.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è Sitting-78-_jpg.rf.10ab69ef1f703c4703dec2e68c501292.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-624-_jpg.rf.4ec0b4a331798c7ae7537c32b25ff3b5.jpg: 640x640 1 person, 176.1ms\n",
      "Speed: 0.6ms preprocess, 176.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0669_JPG.rf.a74fdb7c5fea03bca982d6a6375225c3.jpg: 640x640 1 person, 171.1ms\n",
      "Speed: 0.7ms preprocess, 171.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0631_JPG.rf.1915b91bb9e9c76d80fc214353b2151f.jpg: 640x640 1 person, 173.6ms\n",
      "Speed: 0.6ms preprocess, 173.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/16_jpg.rf.6816f7a7386fa283686d0b024ca86479.jpg: 640x640 1 person, 172.1ms\n",
      "Speed: 0.8ms preprocess, 172.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/55_jpg.rf.328ad9422dc2c53f99c8fa4265bff94c.jpg: 640x640 2 persons, 174.8ms\n",
      "Speed: 0.7ms preprocess, 174.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/00092_png_jpg.rf.15ba942fc3ba32c3fb3aa71b1d614c19.jpg: 640x640 1 person, 196.4ms\n",
      "Speed: 0.8ms preprocess, 196.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9862_jpg.rf.1f5a0536c3f14c58cacd5d7fde90b500.jpg: 640x640 1 person, 165.0ms\n",
      "Speed: 0.7ms preprocess, 165.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0680_JPG.rf.bb60e9441dd9e0a7d7ec9647e7404e40.jpg: 640x640 1 person, 171.5ms\n",
      "Speed: 0.6ms preprocess, 171.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/59_jpg.rf.0bd2f03ab087e0cdd67512ef5e34d55c.jpg: 640x640 1 person, 172.8ms\n",
      "Speed: 0.7ms preprocess, 172.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe53_jpg.rf.1cf324cf4a7500d465d9debc64c1f46a.jpg: 640x640 1 person, 170.9ms\n",
      "Speed: 0.7ms preprocess, 170.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-163-_jpg.rf.91fefc48309bc9188e9da1c112864d69.jpg: 640x640 1 person, 174.4ms\n",
      "Speed: 0.8ms preprocess, 174.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-206-_jpg.rf.95fe70b4cc41e70a74c97a561271b9ab.jpg: 640x640 6 persons, 176.3ms\n",
      "Speed: 0.7ms preprocess, 176.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/bad_posture_20241013_222737_png.rf.afdb7163fe6d87d4423f6c7287b5846d.jpg: 640x640 2 persons, 174.5ms\n",
      "Speed: 0.7ms preprocess, 174.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0022_jpg.rf.6cc4fcf21d6c7de31b4274587da8b1e3.jpg: 640x640 1 person, 172.0ms\n",
      "Speed: 0.7ms preprocess, 172.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-104540_jpg.rf.0f2ba67351fb805fde6b820235cc4ce1.jpg: 640x640 1 person, 173.6ms\n",
      "Speed: 0.7ms preprocess, 173.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17195253771829298_jpg.rf.ce283bc75d2cf4d7eec8881763382b44.jpg: 640x640 (no detections), 178.1ms\n",
      "Speed: 0.7ms preprocess, 178.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 17195253771829298_jpg.rf.ce283bc75d2cf4d7eec8881763382b44.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-219-_jpg.rf.4e38427818eea8994d928d5fffbd25a4.jpg: 640x640 1 person, 181.9ms\n",
      "Speed: 0.7ms preprocess, 181.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0698_JPG.rf.57cbb9aea450930340f872c909bbae48.jpg: 640x640 1 person, 179.0ms\n",
      "Speed: 0.7ms preprocess, 179.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17195253703088033_jpg.rf.8709a524b7d933c5bb8712734bcb3744.jpg: 640x640 (no detections), 184.1ms\n",
      "Speed: 0.6ms preprocess, 184.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 17195253703088033_jpg.rf.8709a524b7d933c5bb8712734bcb3744.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/alex-avalos-Dn2J7rMU6ME-unsplash_jpg.rf.69a9641edce8890e72161a06092732e2.jpg: 640x640 1 person, 183.3ms\n",
      "Speed: 0.7ms preprocess, 183.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0035_jpg.rf.bd591bffc1631570d0926af551871510.jpg: 640x640 1 person, 174.7ms\n",
      "Speed: 0.7ms preprocess, 174.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0033_jpg.rf.51f18697f3cd490b513033203101613d.jpg: 640x640 2 persons, 169.6ms\n",
      "Speed: 0.6ms preprocess, 169.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0052_jpg.rf.e887e0dca9c724979e1195680bf0107d.jpg: 640x640 1 person, 165.5ms\n",
      "Speed: 0.6ms preprocess, 165.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0008_jpg.rf.7a2f96ceb6b6e22cab965b7d4c143c0a.jpg: 640x640 1 person, 179.9ms\n",
      "Speed: 0.6ms preprocess, 179.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9857_jpg.rf.19001b3f3f9f5f098c9d8d092a2ca307.jpg: 640x640 1 person, 199.7ms\n",
      "Speed: 0.6ms preprocess, 199.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-105116_jpg.rf.dd87f368edd4bf969a9c6d219eb711f1.jpg: 640x640 1 person, 176.0ms\n",
      "Speed: 0.7ms preprocess, 176.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/images-24-_jpg.rf.30ec6269528cc62ea805314d3b3fb2ff.jpg: 640x640 1 person, 177.3ms\n",
      "Speed: 0.7ms preprocess, 177.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0030_jpg.rf.31b5a03588c3b28e1406487398b59daf.jpg: 640x640 1 person, 195.9ms\n",
      "Speed: 0.7ms preprocess, 195.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9854_jpg.rf.1d9c25ba631ddffa869e78fbe89ff59e.jpg: 640x640 1 person, 178.7ms\n",
      "Speed: 0.8ms preprocess, 178.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0555_JPG.rf.901d3867f462ec6ce9facea646805b8c.jpg: 640x640 2 persons, 178.7ms\n",
      "Speed: 0.7ms preprocess, 178.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/bad_posture_20241021_141737_png.rf.b24d136cf2bb317f5b378c1443886528.jpg: 640x640 1 person, 181.6ms\n",
      "Speed: 0.6ms preprocess, 181.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/images_jpg.rf.f4899cf04551271d6f8dc64d13b16909.jpg: 640x640 1 person, 180.0ms\n",
      "Speed: 0.6ms preprocess, 180.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è images_jpg.rf.f4899cf04551271d6f8dc64d13b16909.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-250-_jpg.rf.305ff7e0d98c78121c31f09acd0d5688.jpg: 640x640 1 person, 175.5ms\n",
      "Speed: 0.7ms preprocess, 175.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17195260984684012_jpg.rf.01e58c476e0cdcf9730bc1ceb019cc70.jpg: 640x640 (no detections), 179.0ms\n",
      "Speed: 0.6ms preprocess, 179.0ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 17195260984684012_jpg.rf.01e58c476e0cdcf9730bc1ceb019cc70.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-104417_jpg.rf.cff9d92938964a5cc753ebab033ff4bf.jpg: 640x640 1 person, 187.5ms\n",
      "Speed: 0.8ms preprocess, 187.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9867_jpg.rf.8b65ce175f0ef15cca9d4bb5f2032470.jpg: 640x480 1 person, 138.1ms\n",
      "Speed: 0.6ms preprocess, 138.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-964-_jpg.rf.560d13fb9398ff648de0e1248e9a49f5.jpg: 640x640 2 persons, 181.7ms\n",
      "Speed: 0.6ms preprocess, 181.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-642-_jpg.rf.adbee23c6db3ac4de8dbe086fa84cb39.jpg: 640x640 5 persons, 194.2ms\n",
      "Speed: 0.7ms preprocess, 194.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-166-_jpg.rf.a6e4844d2d09d9cee9f8c5311459ff51.jpg: 640x640 4 persons, 193.4ms\n",
      "Speed: 0.6ms preprocess, 193.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-661-_jpg.rf.6400f432600a01c537ad6361f28c9ff5.jpg: 640x640 1 person, 198.7ms\n",
      "Speed: 0.6ms preprocess, 198.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0008_jpg.rf.6ff270af05274d20670786bb6d9a4f75.jpg: 640x640 3 persons, 214.3ms\n",
      "Speed: 0.7ms preprocess, 214.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0044_jpg.rf.36854756cb3c20a445ed6c8712f70000.jpg: 640x640 1 person, 184.2ms\n",
      "Speed: 0.7ms preprocess, 184.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/18_jpg.rf.1c52e86d5687f1513d071005ec122061.jpg: 640x640 1 person, 223.1ms\n",
      "Speed: 0.7ms preprocess, 223.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17195260950112104_jpg.rf.8d443b5a6aa4f9398ad01997bdef6db0.jpg: 640x640 (no detections), 216.5ms\n",
      "Speed: 0.6ms preprocess, 216.5ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 17195260950112104_jpg.rf.8d443b5a6aa4f9398ad01997bdef6db0.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1719525373749678_jpg.rf.ff60a2eb345f24649c2f1e2c6b38a3cd.jpg: 640x640 1 person, 248.9ms\n",
      "Speed: 1.1ms preprocess, 248.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-92-_jpg.rf.377b67a929e4af213cfb41512d2dd574.jpg: 640x640 1 person, 189.9ms\n",
      "Speed: 0.7ms preprocess, 189.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-from-2022-07-18-00-37-59_jpg.rf.7062aad72b5f76e3da2e16b2c54c49f4.jpg: 640x640 1 person, 189.8ms\n",
      "Speed: 0.7ms preprocess, 189.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/images-20-_JPG_jpg.rf.729ec8bad18c3dbbfc10a7f779f4898f.jpg: 640x640 1 person, 224.6ms\n",
      "Speed: 0.6ms preprocess, 224.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-246-_jpg.rf.ee4a472971e4fc0525b532dda7ca7db5.jpg: 640x640 1 person, 206.9ms\n",
      "Speed: 0.6ms preprocess, 206.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-104023_jpg.rf.72c670aa03527aef222f0fee9d987add.jpg: 640x640 1 person, 208.7ms\n",
      "Speed: 0.6ms preprocess, 208.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-104106_jpg.rf.05c918c6f7f910f4401552e2fa632cc6.jpg: 640x640 1 person, 220.2ms\n",
      "Speed: 0.8ms preprocess, 220.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/val03_png_jpg.rf.48b87c786543ddfa599767f6e4b25c2c.jpg: 640x640 1 person, 189.3ms\n",
      "Speed: 0.9ms preprocess, 189.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe25_jpg.rf.de995663db3346612db5232fc72f2a6a.jpg: 640x640 1 person, 189.8ms\n",
      "Speed: 1.2ms preprocess, 189.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17195253703088033_jpg.rf.0fc46381d9afde53d968d939f7265b20.jpg: 640x640 (no detections), 190.2ms\n",
      "Speed: 0.8ms preprocess, 190.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 17195253703088033_jpg.rf.0fc46381d9afde53d968d939f7265b20.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0676_JPG.rf.0b7f2761f542e523f1351c3a89127fcf.jpg: 640x640 1 person, 202.1ms\n",
      "Speed: 0.7ms preprocess, 202.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-26-_jpg.rf.8bf9376ea4dc29f2b080dbd94ccb59f0.jpg: 640x640 1 person, 184.4ms\n",
      "Speed: 0.7ms preprocess, 184.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-549-_jpg.rf.238b9591114b0e59b81cb66cbe3a14e1.jpg: 640x640 1 person, 193.3ms\n",
      "Speed: 0.6ms preprocess, 193.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1000_F_563039522_qgb9jDquq6naCBkvLCuEWKBzJFl5yu8N_jpg.rf.1206d57b0052ce19e6e2f1adafba51b8.jpg: 640x640 1 person, 189.6ms\n",
      "Speed: 0.8ms preprocess, 189.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17195253690526876_jpg.rf.ffb4d596423709c579f454e52e7f5346.jpg: 640x640 (no detections), 190.8ms\n",
      "Speed: 0.7ms preprocess, 190.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 17195253690526876_jpg.rf.ffb4d596423709c579f454e52e7f5346.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-25-_jpg.rf.db17ac3f405606cf140ecaf744a4d0d6.jpg: 640x640 1 person, 186.4ms\n",
      "Speed: 0.6ms preprocess, 186.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-373-_jpg.rf.8723021ef7d35c96ab7c4965cfc7835f.jpg: 640x640 1 person, 222.8ms\n",
      "Speed: 0.7ms preprocess, 222.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/11_jpg.rf.471265bad54d3c83231f2818eb4caf30.jpg: 640x640 2 persons, 200.0ms\n",
      "Speed: 0.8ms preprocess, 200.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-105054_jpg.rf.4804281564acc01ba2e694380d7014b1.jpg: 640x640 1 person, 229.1ms\n",
      "Speed: 0.7ms preprocess, 229.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0022_jpg.rf.b1e28e2c0807d409dd910f7d6d4a4c9b.jpg: 640x640 1 person, 206.0ms\n",
      "Speed: 0.7ms preprocess, 206.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-104649_jpg.rf.abd84d3f1b935b6530e9bc1c19676604.jpg: 640x640 1 person, 190.8ms\n",
      "Speed: 0.8ms preprocess, 190.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0602_JPG.rf.bd64f34b9e653865705764c9ead6c893.jpg: 640x640 1 person, 191.2ms\n",
      "Speed: 0.7ms preprocess, 191.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0016_jpg.rf.130729aca8254e88ba52d7045c1d3dc1.jpg: 640x640 1 person, 225.8ms\n",
      "Speed: 0.8ms preprocess, 225.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9859_jpg.rf.7c93829e971a4c6cbbbc5186aa38c197.jpg: 640x640 1 person, 236.8ms\n",
      "Speed: 0.6ms preprocess, 236.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/mala-postura-354-_jpg.rf.cb5fafd5909539c9e8ef3aa72dc9b2bd.jpg: 640x640 1 person, 225.4ms\n",
      "Speed: 0.9ms preprocess, 225.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0027_jpg.rf.fdcafe530af484590d0c312476f5a99f.jpg: 640x640 1 person, 240.6ms\n",
      "Speed: 1.0ms preprocess, 240.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0531_JPG.rf.32798223cef871b74182aec0c2956ca3.jpg: 640x640 1 person, 228.6ms\n",
      "Speed: 1.2ms preprocess, 228.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1000_F_875541865_mRTpOX4QlcLKpda1Sf3NSxs5zHx9REo6_jpg.rf.38e1e2bf4fc31b457d2ef284cf15b84c.jpg: 640x640 1 person, 196.3ms\n",
      "Speed: 1.7ms preprocess, 196.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 1000_F_875541865_mRTpOX4QlcLKpda1Sf3NSxs5zHx9REo6_jpg.rf.38e1e2bf4fc31b457d2ef284cf15b84c.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0655_JPG.rf.2afb78f4c33700aa24b2f13ef0474c64.jpg: 640x640 1 person, 188.1ms\n",
      "Speed: 0.6ms preprocess, 188.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17195260969006755_jpg.rf.c486539f4a88fcc27267b248f0eb4b13.jpg: 640x640 (no detections), 188.7ms\n",
      "Speed: 0.9ms preprocess, 188.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 17195260969006755_jpg.rf.c486539f4a88fcc27267b248f0eb4b13.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe18_jpg.rf.bbbe7cc888c6fd3f5c72fc5a1cc023e7.jpg: 640x640 1 person, 223.8ms\n",
      "Speed: 0.9ms preprocess, 223.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9871_jpg.rf.b41f29e3013cb2690447ef6d9951357a.jpg: 640x640 1 person, 229.2ms\n",
      "Speed: 0.7ms preprocess, 229.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-322-_jpg.rf.f3e7b0c83496b469c474d7fb00879e5d.jpg: 640x640 1 person, 222.7ms\n",
      "Speed: 0.8ms preprocess, 222.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0031_jpg.rf.fcfa667944c606d7e33c50c5f494d282.jpg: 640x640 2 persons, 219.7ms\n",
      "Speed: 0.7ms preprocess, 219.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/2_jpg.rf.d7629654f49609f7ae1f9b5e41feed98.jpg: 640x640 1 person, 194.4ms\n",
      "Speed: 0.6ms preprocess, 194.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0634_JPG.rf.de98c4dcc4a732f25ad371ff2a8fbdbe.jpg: 640x640 1 person, 192.1ms\n",
      "Speed: 0.7ms preprocess, 192.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9856_jpg.rf.7bb626472951faeba402bd631aac5cce.jpg: 640x640 1 person, 191.0ms\n",
      "Speed: 0.7ms preprocess, 191.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/good_posture_20241012_174341_png.rf.7836a7394e382f9eec3390753ca195b8.jpg: 640x640 1 person, 192.7ms\n",
      "Speed: 0.6ms preprocess, 192.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-208-_jpg.rf.98c2e68c8c7639006fdfc7692a65215c.jpg: 640x640 2 persons, 190.0ms\n",
      "Speed: 0.8ms preprocess, 190.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-300-_jpg.rf.f860f22ca8bcbf23306c26884ec1aaaf.jpg: 640x640 13 persons, 203.5ms\n",
      "Speed: 0.6ms preprocess, 203.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è Sitting-300-_jpg.rf.f860f22ca8bcbf23306c26884ec1aaaf.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "‚ö†Ô∏è Sitting-300-_jpg.rf.f860f22ca8bcbf23306c26884ec1aaaf.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "‚ö†Ô∏è Sitting-300-_jpg.rf.f860f22ca8bcbf23306c26884ec1aaaf.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "‚ö†Ô∏è Sitting-300-_jpg.rf.f860f22ca8bcbf23306c26884ec1aaaf.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/300903280-613021353669560-190601146662061164-n_d25c386f2f814735af34bd1f77e94ad2_webp.rf.4043a4968f5f58a37c1e7dc573c4b1bd.jpg: 640x640 1 person, 200.2ms\n",
      "Speed: 0.9ms preprocess, 200.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-986-_jpg.rf.4de2d9e06b609a8333ee80fccb1111df.jpg: 640x640 1 person, 217.9ms\n",
      "Speed: 0.6ms preprocess, 217.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-91-_jpg.rf.81f70bc244a1ef0ef9577447b6807cb3.jpg: 640x640 1 person, 194.7ms\n",
      "Speed: 0.7ms preprocess, 194.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-151-_jpg.rf.17d46b83bbb3fab591ed9fe48820138f.jpg: 640x640 6 persons, 186.8ms\n",
      "Speed: 0.7ms preprocess, 186.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è Sitting-151-_jpg.rf.17d46b83bbb3fab591ed9fe48820138f.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/image_20241007_222646_jpg.rf.9fe916d75a4559a3431591303ca996b0.jpg: 640x640 1 person, 195.3ms\n",
      "Speed: 0.6ms preprocess, 195.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-214-_jpg.rf.bb1a35d635bbec203c04302782c4dc54.jpg: 640x640 1 person, 196.3ms\n",
      "Speed: 0.7ms preprocess, 196.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/bad_posture_20241021_142555_png.rf.b81996769ce20ec51609c9d129b2c1b9.jpg: 640x640 1 person, 189.1ms\n",
      "Speed: 0.8ms preprocess, 189.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe54_jpg.rf.6a69cdfd33b2bbc63068b83ae91badb3.jpg: 640x640 2 persons, 190.4ms\n",
      "Speed: 0.8ms preprocess, 190.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-644-_jpg.rf.c90d9e8bb4209e72c6220475bd2b0ac8.jpg: 640x640 4 persons, 194.3ms\n",
      "Speed: 0.7ms preprocess, 194.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-72-_jpg.rf.8d344a7fa05e2b32590efcaf1b082777.jpg: 640x640 1 person, 191.9ms\n",
      "Speed: 0.8ms preprocess, 191.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-339-_jpg.rf.d22750b65577097a729f2a8980c0d955.jpg: 640x640 1 person, 182.6ms\n",
      "Speed: 0.6ms preprocess, 182.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/images-1-_jpg.rf.5cc5f80551a585c0a2f22f4c2ccb29cb.jpg: 640x640 1 person, 192.6ms\n",
      "Speed: 0.7ms preprocess, 192.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe39_jpg.rf.5cbdd726bf6ef827f783ebae0f03276e.jpg: 640x640 1 person, 196.0ms\n",
      "Speed: 0.7ms preprocess, 196.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/55_jpg.rf.9c8aaaa8bfcc49537ed2304332aa20d0.jpg: 640x640 1 person, 192.0ms\n",
      "Speed: 0.6ms preprocess, 192.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-133-_jpg.rf.250b633e6c5eb7980d4ba4be06a6c13b.jpg: 640x640 1 person, 208.2ms\n",
      "Speed: 0.6ms preprocess, 208.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9857_jpg.rf.c2cbf306d6bb03ed73e2367182befdef.jpg: 640x480 1 person, 150.9ms\n",
      "Speed: 0.6ms preprocess, 150.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-105429_jpg.rf.46fb0dc6e599a93c6b1531f98ec25dda.jpg: 640x640 1 person, 200.7ms\n",
      "Speed: 0.6ms preprocess, 200.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0696_JPG.rf.51daf2b86d80d532e56fa953b0404db3.jpg: 640x640 1 person, 195.3ms\n",
      "Speed: 0.7ms preprocess, 195.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0103_jpg.rf.44dc495e1c16a1844daed8805d3726c5.jpg: 640x640 2 persons, 194.7ms\n",
      "Speed: 0.8ms preprocess, 194.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/12_jpg.rf.1dd10c8ef694c5ccf91692d86dd9d7ee.jpg: 640x640 1 person, 191.1ms\n",
      "Speed: 0.7ms preprocess, 191.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-23-_jpg.rf.bfff4ba654204586953b9a569835b8f9.jpg: 640x640 1 person, 193.0ms\n",
      "Speed: 0.8ms preprocess, 193.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/LINE_ALBUM_202452_240502_46_jpg.rf.ffd9676ef8d21d2e0dd11085427b579a.jpg: 640x640 1 person, 180.9ms\n",
      "Speed: 0.7ms preprocess, 180.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-284-_jpg.rf.4e8cde3cc5ea27e0d0c5a429d4098ec6.jpg: 640x640 1 person, 183.0ms\n",
      "Speed: 0.7ms preprocess, 183.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/9_jpg.rf.1e3b1396757e0d67be38cdeceb63d892.jpg: 640x640 1 person, 184.1ms\n",
      "Speed: 0.7ms preprocess, 184.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/13_jpg.rf.424f78a273fdbba5b9a46e518fcfbfe6.jpg: 640x640 1 person, 186.5ms\n",
      "Speed: 0.6ms preprocess, 186.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-832-_jpg.rf.255a2f75810fe144c88e11b2f63673d2.jpg: 640x640 2 persons, 187.3ms\n",
      "Speed: 0.8ms preprocess, 187.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Tips-for-improving-your-sitting-posture-1024x1024_jpg.rf.9394c28e3d56dd9f0207d2eee87a0287.jpg: 640x640 1 person, 177.8ms\n",
      "Speed: 0.6ms preprocess, 177.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è Tips-for-improving-your-sitting-posture-1024x1024_jpg.rf.9394c28e3d56dd9f0207d2eee87a0287.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe21_jpg.rf.b2869d4ebb93f05bad05143104f1ae41.jpg: 640x640 1 person, 171.6ms\n",
      "Speed: 0.6ms preprocess, 171.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe44_jpg.rf.f1c671c9d1058bddcea46245af07dd24.jpg: 640x640 1 person, 191.2ms\n",
      "Speed: 0.8ms preprocess, 191.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/images-2-_jpg.rf.b5481e747dde03dbf7154905ae8dfec3.jpg: 640x640 1 person, 192.2ms\n",
      "Speed: 0.6ms preprocess, 192.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0026_jpg.rf.79b570f91236dbf487e14ddfaa5c3153.jpg: 640x640 3 persons, 189.6ms\n",
      "Speed: 0.7ms preprocess, 189.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0007_jpg.rf.153138797be13437492f67b1fdd2e60e.jpg: 640x640 3 persons, 181.4ms\n",
      "Speed: 0.8ms preprocess, 181.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0017_jpg.rf.481cf358f16f9d06e8e60f3d9ce465d6.jpg: 640x640 1 person, 190.1ms\n",
      "Speed: 0.9ms preprocess, 190.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1719525373018024_jpg.rf.566c4dcefaaeba40cc37dad51d7e4f79.jpg: 640x640 (no detections), 171.7ms\n",
      "Speed: 0.6ms preprocess, 171.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 1719525373018024_jpg.rf.566c4dcefaaeba40cc37dad51d7e4f79.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/man-bad-proper-posture-on-260nw-1969584031_webp.rf.cc703da2ac071b817ecaf9b07cd4a1c3.jpg: 640x640 2 persons, 172.1ms\n",
      "Speed: 0.6ms preprocess, 172.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è man-bad-proper-posture-on-260nw-1969584031_webp.rf.cc703da2ac071b817ecaf9b07cd4a1c3.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "‚ö†Ô∏è man-bad-proper-posture-on-260nw-1969584031_webp.rf.cc703da2ac071b817ecaf9b07cd4a1c3.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/20230415094334_jpg.rf.f8b569f19a0af2a4aeff752d533a9575.jpg: 640x640 2 persons, 176.5ms\n",
      "Speed: 0.6ms preprocess, 176.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/images-18-_JPG_jpg.rf.84e59b7978db903cc90db7bffa1e53d6.jpg: 640x640 2 persons, 192.5ms\n",
      "Speed: 0.6ms preprocess, 192.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è images-18-_JPG_jpg.rf.84e59b7978db903cc90db7bffa1e53d6.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/WhatsApp-Image-2023-10-16-at-17-04-16_jpeg.rf.a24926954c0ed24381bd5e3b693e7deb.jpg: 640x640 2 persons, 188.5ms\n",
      "Speed: 0.7ms preprocess, 188.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-150-_jpg.rf.e86aeb609ff174bd9f34be7587cf649c.jpg: 640x640 1 person, 185.4ms\n",
      "Speed: 0.7ms preprocess, 185.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe54_jpg.rf.a6f5c395bf7e0607a82f03fe1708cbbd.jpg: 640x640 1 person, 178.2ms\n",
      "Speed: 0.7ms preprocess, 178.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0137_jpg.rf.33016418571284c659f555198774140e.jpg: 640x640 4 persons, 170.0ms\n",
      "Speed: 0.8ms preprocess, 170.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0028_jpg.rf.53a565bfeac9bc630ff81d521bd00458.jpg: 640x640 1 person, 172.1ms\n",
      "Speed: 0.6ms preprocess, 172.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17195253726924543_jpg.rf.6b36fc9510a81877434b93456071a7ef.jpg: 640x640 (no detections), 173.8ms\n",
      "Speed: 0.7ms preprocess, 173.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 17195253726924543_jpg.rf.6b36fc9510a81877434b93456071a7ef.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/32_jpg.rf.6908917ec3b48e0075d035eae8fdf2f0.jpg: 640x640 1 person, 177.1ms\n",
      "Speed: 0.8ms preprocess, 177.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-104523_jpg.rf.ee1398957f6bc7076992c841ea90d1dc.jpg: 640x640 1 person, 174.4ms\n",
      "Speed: 0.6ms preprocess, 174.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/bad_posture_20241012_173222_png.rf.7a70a0fbb1c221bb87c32fcf855bb23d.jpg: 640x640 1 person, 170.7ms\n",
      "Speed: 0.6ms preprocess, 170.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/-_yythkg_jpg.rf.46fec038ddf6f50f99ba5546ac1d362d.jpg: 640x640 1 person, 170.5ms\n",
      "Speed: 0.6ms preprocess, 170.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17195260990530465_jpg.rf.66e3dbed05b2444e42c4a780f33b01d9.jpg: 640x640 1 person, 186.9ms\n",
      "Speed: 0.6ms preprocess, 186.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/bad_posture_20241012_174037_png.rf.0fae5635639411154db493d6f3f0ace9.jpg: 640x640 1 person, 185.2ms\n",
      "Speed: 0.9ms preprocess, 185.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe39_jpg.rf.4d681e9fb46bb93875e5a4990979207f.jpg: 640x640 1 person, 183.2ms\n",
      "Speed: 0.7ms preprocess, 183.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/20230415092256_jpg.rf.5a0378d0f4255904d5b7ea23e108fe7f.jpg: 640x640 3 persons, 211.3ms\n",
      "Speed: 0.9ms preprocess, 211.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 20230415092256_jpg.rf.5a0378d0f4255904d5b7ea23e108fe7f.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/train03_png_jpg.rf.b755bf75408100a9fc8ef2531bf2d767.jpg: 640x640 3 persons, 175.1ms\n",
      "Speed: 0.6ms preprocess, 175.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è train03_png_jpg.rf.b755bf75408100a9fc8ef2531bf2d767.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-664-_jpg.rf.815acaa3c27d49b9855b14ec49bb2aea.jpg: 640x640 1 person, 173.6ms\n",
      "Speed: 0.7ms preprocess, 173.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/00003_png_jpg.rf.5ecdc9a19b55712638548f505ae8978b.jpg: 640x640 2 persons, 168.3ms\n",
      "Speed: 0.6ms preprocess, 168.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0689_JPG.rf.be23016740542ba084046dc6aab7274b.jpg: 640x640 1 person, 172.2ms\n",
      "Speed: 0.6ms preprocess, 172.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0121_jpg.rf.bf91e8c3cd7c8814c22ef8cf5150099a.jpg: 640x640 3 persons, 178.6ms\n",
      "Speed: 0.7ms preprocess, 178.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pc78_jpg.rf.15151b271a4f6ed9fba336d49cf18755.jpg: 640x640 2 persons, 175.9ms\n",
      "Speed: 0.6ms preprocess, 175.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0074_jpg.rf.d8c9583e2a3f9ec240959de2891523f7.jpg: 640x640 2 persons, 188.4ms\n",
      "Speed: 0.6ms preprocess, 188.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/good_posture_20241021_142205_png.rf.e2d921443f2d1d58bfa39d81d893f316.jpg: 640x640 1 person, 182.8ms\n",
      "Speed: 0.8ms preprocess, 182.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è good_posture_20241021_142205_png.rf.e2d921443f2d1d58bfa39d81d893f316.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-843-_jpg.rf.99a903715b49968f5cc56472af770178.jpg: 640x640 1 person, 176.8ms\n",
      "Speed: 0.8ms preprocess, 176.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting88_jpg.rf.c18aead17d8a9c2439cd5ec8ef6ddae8.jpg: 640x640 1 person, 186.9ms\n",
      "Speed: 0.6ms preprocess, 186.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-599-_jpg.rf.1fb9a94ad2d4f08563449881135b521a.jpg: 640x640 2 persons, 180.4ms\n",
      "Speed: 0.7ms preprocess, 180.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-104556_jpg.rf.732681373fa8546e6f48aac766a49e87.jpg: 640x640 1 person, 176.8ms\n",
      "Speed: 0.6ms preprocess, 176.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/image_20241008_205202_jpg.rf.dee23115ae31adcfe709a456d1322fa3.jpg: 640x640 1 person, 176.9ms\n",
      "Speed: 0.7ms preprocess, 176.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/45_jpg.rf.fcbfb4a3b3cc25b74b15228f48f6f6ab.jpg: 640x640 1 person, 179.0ms\n",
      "Speed: 0.7ms preprocess, 179.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 45_jpg.rf.fcbfb4a3b3cc25b74b15228f48f6f6ab.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/images-1-_jpg.rf.86a09263f4d9ddc6225fd25d99d05169.jpg: 448x640 1 person, 123.6ms\n",
      "Speed: 0.4ms preprocess, 123.6ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/21_jpg.rf.aaae9bb29217fe97598c21e2f4754c15.jpg: 640x640 1 person, 170.4ms\n",
      "Speed: 0.6ms preprocess, 170.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 21_jpg.rf.aaae9bb29217fe97598c21e2f4754c15.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-684-_jpg.rf.616432dfa04d369a2e94e070962f4e57.jpg: 640x640 1 person, 179.9ms\n",
      "Speed: 0.7ms preprocess, 179.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-475-_jpg.rf.a54a56b10c51f28f73ab80105f0c8147.jpg: 640x640 1 person, 188.2ms\n",
      "Speed: 0.6ms preprocess, 188.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe18_jpg.rf.e0efe0ea7562546c30b63a232b1c0330.jpg: 640x640 1 person, 183.7ms\n",
      "Speed: 0.7ms preprocess, 183.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-318-_jpg.rf.75593f56b20e12feb5fa073d22934d5c.jpg: 640x640 4 persons, 199.3ms\n",
      "Speed: 0.7ms preprocess, 199.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/images-15-_JPG_jpg.rf.f1979259c8cf508f6a0e5676f16a2d8d.jpg: 640x640 1 person, 173.5ms\n",
      "Speed: 0.6ms preprocess, 173.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è images-15-_JPG_jpg.rf.f1979259c8cf508f6a0e5676f16a2d8d.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17195260946510482_jpg.rf.b41489e80c72379ac208a7bbb715fc9a.jpg: 640x640 (no detections), 170.5ms\n",
      "Speed: 0.7ms preprocess, 170.5ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 17195260946510482_jpg.rf.b41489e80c72379ac208a7bbb715fc9a.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/val03_png.rf.a431904320133e134877902258632899.jpg: 640x480 1 person, 127.4ms\n",
      "Speed: 0.5ms preprocess, 127.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0004_jpg.rf.7ead7672002844056235d05fd358b1de.jpg: 640x640 2 persons, 206.5ms\n",
      "Speed: 0.6ms preprocess, 206.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-371-_jpg.rf.d5925a2b23c0ece493f81029cdb316b4.jpg: 640x640 3 persons, 183.7ms\n",
      "Speed: 0.8ms preprocess, 183.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-106-_jpg.rf.143e59fc7c9587f9740b7bc6adc73991.jpg: 640x640 3 persons, 181.3ms\n",
      "Speed: 0.6ms preprocess, 181.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0040_jpg.rf.482df7ab55b28c9896de55c22a452d99.jpg: 640x640 1 person, 182.0ms\n",
      "Speed: 0.9ms preprocess, 182.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0637_JPG.rf.3230a3b1cb4a894379efecb674d37275.jpg: 640x640 1 person, 172.2ms\n",
      "Speed: 0.7ms preprocess, 172.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-995-_jpg.rf.37d39844994ec7ba1ed09b91d37a627d.jpg: 640x640 1 person, 167.4ms\n",
      "Speed: 0.7ms preprocess, 167.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/bad_posture_20241021_144407_png.rf.91d2f72d59fca285306fd21eefcf4b4e.jpg: 640x640 1 person, 170.6ms\n",
      "Speed: 0.7ms preprocess, 170.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1000_F_143228957_9LGCdajpw51xHsQXBy1vcPMO0Ywtx1ox_jpg.rf.f0756dd6e6800f50958ef01c939966f2.jpg: 640x640 1 person, 170.5ms\n",
      "Speed: 0.6ms preprocess, 170.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17195253726924543_jpg.rf.b33b670194c6f5cad6b1ab47e48b90e2.jpg: 640x640 (no detections), 176.5ms\n",
      "Speed: 0.8ms preprocess, 176.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 17195253726924543_jpg.rf.b33b670194c6f5cad6b1ab47e48b90e2.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/29_jpg.rf.e9378682f70a1b08081677cf19925900.jpg: 640x640 2 persons, 184.8ms\n",
      "Speed: 0.7ms preprocess, 184.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 29_jpg.rf.e9378682f70a1b08081677cf19925900.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/good_posture_20241021_180318_png.rf.e7960e2213b5374432299374c72ddc74.jpg: 640x640 1 person, 176.4ms\n",
      "Speed: 0.6ms preprocess, 176.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/-_-_-_jpg.rf.e51f7880e7a2938b0f5701f1db687ef6.jpg: 640x640 1 person, 169.8ms\n",
      "Speed: 0.7ms preprocess, 169.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0684_JPG.rf.9797c1ed48b87a0c3f3cb5311648f42a.jpg: 640x640 1 person, 168.7ms\n",
      "Speed: 0.7ms preprocess, 168.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/img-6-_jpg.rf.50c82424f9d86df86824549866d3efe8.jpg: 640x640 2 persons, 173.8ms\n",
      "Speed: 0.6ms preprocess, 173.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-947-_jpg.rf.183de464e92531fe91f8a66f013b23f9.jpg: 640x640 1 person, 176.3ms\n",
      "Speed: 0.6ms preprocess, 176.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/image_20241008_202338_jpg.rf.a9b73f4bdc09b91839a3b80b7f63b65e.jpg: 640x640 1 person, 186.0ms\n",
      "Speed: 0.6ms preprocess, 186.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Standing-106-_jpg.rf.80a84a1bb9f3e145f73bb7842c03354d.jpg: 640x640 2 persons, 174.3ms\n",
      "Speed: 0.8ms preprocess, 174.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è Standing-106-_jpg.rf.80a84a1bb9f3e145f73bb7842c03354d.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-743-_jpg.rf.9a7ea9fb86af52598c033398b31875c0.jpg: 640x640 3 persons, 170.3ms\n",
      "Speed: 0.7ms preprocess, 170.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-783-_jpg.rf.ed242d598cd13726d2a4a4f75a7da5aa.jpg: 640x640 1 person, 170.2ms\n",
      "Speed: 0.7ms preprocess, 170.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/12_jpg.rf.5ce61f8dcde87ac9a9b50ac199ae7a68.jpg: 640x640 1 person, 168.0ms\n",
      "Speed: 0.8ms preprocess, 168.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/-_JPG_jpg.rf.74dea411b3050b5b236928a89f7a84ff.jpg: 640x640 1 person, 181.3ms\n",
      "Speed: 0.7ms preprocess, 181.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Pic-2020-Sep-11-1-26ee7bc6dc178a4de7fa45e964e6bf84_jpg.rf.06575c2c811a44b32fb9953970643529.jpg: 480x640 1 person, 130.1ms\n",
      "Speed: 0.5ms preprocess, 130.1ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0659_JPG.rf.80e9f1a0dedbe8c4888aa7ee6ee8015e.jpg: 640x640 1 person, 189.1ms\n",
      "Speed: 0.5ms preprocess, 189.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0015_jpg.rf.07781b27165b5a921e51a867d74277ab.jpg: 640x640 1 person, 187.5ms\n",
      "Speed: 0.7ms preprocess, 187.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/christina-wocintechchat-com-y3YyxZA7bjs-unsplash_jpg.rf.763dfec1d53b2d263e512426c63d5551.jpg: 640x640 2 persons, 179.0ms\n",
      "Speed: 0.6ms preprocess, 179.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/images-2-_jpg.rf.fbc5b4b7cbd102c8ec497944d04d851a.jpg: 640x640 1 person, 179.8ms\n",
      "Speed: 0.8ms preprocess, 179.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è images-2-_jpg.rf.fbc5b4b7cbd102c8ec497944d04d851a.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/20230415093807_jpg.rf.799391a902f90f77fbc7e352d346eab4.jpg: 640x640 3 persons, 170.6ms\n",
      "Speed: 0.8ms preprocess, 170.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9403-1-768x1024_jpg.rf.c5960ebb7c845bc71e7e389c6ec17fc0.jpg: 640x640 1 person, 170.5ms\n",
      "Speed: 0.6ms preprocess, 170.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0580_JPG.rf.8999e230a8352164b767b357c56140a8.jpg: 640x640 1 person, 173.1ms\n",
      "Speed: 0.7ms preprocess, 173.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/img-7-_jpg.rf.5a53861e9b14a4d13d364c96c4b3cea3.jpg: 640x640 1 person, 173.2ms\n",
      "Speed: 0.6ms preprocess, 173.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/mala-postura-265-_jpg.rf.481695d08a9acc874c2e5012fed495e6.jpg: 640x640 1 person, 174.4ms\n",
      "Speed: 0.8ms preprocess, 174.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/proper-sitting-posture-at-desk_jpg.rf.ab43afc1050fc8d0fab9f89d30cdbb2e.jpg: 640x640 1 person, 172.4ms\n",
      "Speed: 0.7ms preprocess, 172.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0012_jpg.rf.aacfbf32d02a647db37775d112569214.jpg: 640x640 1 person, 171.9ms\n",
      "Speed: 0.6ms preprocess, 171.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/val08_png.rf.6bfb30d06ca4c79bf6176de3530cd095.jpg: 640x416 1 person, 129.2ms\n",
      "Speed: 0.6ms preprocess, 129.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9857_jpg.rf.a5b3ce91edaa7a2ddc3576f67e490aac.jpg: 640x640 1 person, 179.6ms\n",
      "Speed: 0.8ms preprocess, 179.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è IMG_9857_jpg.rf.a5b3ce91edaa7a2ddc3576f67e490aac.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/00073_png_jpg.rf.93d880f5f565fbf8951b66eb83ca2d83.jpg: 640x640 1 person, 206.5ms\n",
      "Speed: 0.7ms preprocess, 206.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/istockphoto-472109363-612x612_jpg.rf.08f6341cfb887bafc30211a7ab2c5d1c.jpg: 640x640 1 person, 171.2ms\n",
      "Speed: 0.7ms preprocess, 171.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è istockphoto-472109363-612x612_jpg.rf.08f6341cfb887bafc30211a7ab2c5d1c.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0668_JPG.rf.47a7f82552147f61b87090528b37d8fa.jpg: 640x640 1 person, 170.5ms\n",
      "Speed: 0.6ms preprocess, 170.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Photo_2567-04-06_01-14-29_AM_jpg.rf.9599d03e303a853e10e5d3c3429942cb.jpg: 640x640 1 person, 171.9ms\n",
      "Speed: 0.6ms preprocess, 171.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-298-_jpg.rf.37fd2efed979bbcde4e852c2844d66bd.jpg: 640x640 1 person, 175.1ms\n",
      "Speed: 0.7ms preprocess, 175.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe31_jpg.rf.7ef6d9e977d26e38ed74c6a811c723d3.jpg: 640x640 1 person, 174.1ms\n",
      "Speed: 0.6ms preprocess, 174.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0644_JPG.rf.b0a5083d69505d86ec5e6436326c4523.jpg: 640x640 1 person, 172.9ms\n",
      "Speed: 0.6ms preprocess, 172.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-959-_jpg.rf.3fce6480677ebdf8cbf649c1f357d214.jpg: 640x640 1 person, 175.7ms\n",
      "Speed: 0.7ms preprocess, 175.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/3_jpg.rf.3472c701285d82653f6f6ce8d9d63f03.jpg: 640x640 1 person, 183.1ms\n",
      "Speed: 0.7ms preprocess, 183.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/25_jpg.rf.b41e0ba6097d9f374a8e01fda2f0279e.jpg: 640x640 2 persons, 180.1ms\n",
      "Speed: 0.6ms preprocess, 180.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/bad_posture_20241021_144550_png.rf.b6731e2f79ff47820cb550355f5961fc.jpg: 640x640 1 person, 180.8ms\n",
      "Speed: 0.8ms preprocess, 180.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-634-_jpg.rf.5aaf70cae828c93ebf40da6a426abd85.jpg: 640x640 2 persons, 172.2ms\n",
      "Speed: 0.7ms preprocess, 172.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-105252_jpg.rf.9879cede7f956fd6f8623e969ed398df.jpg: 640x640 1 person, 171.2ms\n",
      "Speed: 0.6ms preprocess, 171.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0624_JPG.rf.b4d367367a0c394ad1ba7f4ce2708a13.jpg: 640x640 1 person, 172.7ms\n",
      "Speed: 0.6ms preprocess, 172.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-800-_jpg.rf.d7ae850c6afa9a13e4db7bdbd190b20a.jpg: 640x640 1 person, 171.5ms\n",
      "Speed: 0.6ms preprocess, 171.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe46_jpg.rf.427382706149a022c3e9222d1ad26163.jpg: 640x640 1 person, 175.5ms\n",
      "Speed: 0.6ms preprocess, 175.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-110-_jpg.rf.4c1905ddf803f78bb6d63440a678e747.jpg: 640x640 1 person, 168.8ms\n",
      "Speed: 0.6ms preprocess, 168.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-157-_jpg.rf.fc5691b48cbd193440316336fbe81d76.jpg: 640x640 1 person, 163.2ms\n",
      "Speed: 0.7ms preprocess, 163.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/20240829_215717_jpg.rf.6bad2ad1c01d8d4ccd109bfce628f65f.jpg: 640x640 1 person, 179.2ms\n",
      "Speed: 0.7ms preprocess, 179.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/14_jpg.rf.d53aff80f8f5977dff301896c28df465.jpg: 640x640 1 person, 201.2ms\n",
      "Speed: 0.6ms preprocess, 201.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/00063_png_jpg.rf.229aa94225741fbca584b7c5032d21c3.jpg: 640x640 1 person, 183.5ms\n",
      "Speed: 0.8ms preprocess, 183.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Photo_2567-04-06_01-14-29_AM_jpg.rf.c83950f096e7f3b94ace8300010d1396.jpg: 640x640 2 persons, 179.7ms\n",
      "Speed: 0.6ms preprocess, 179.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è Photo_2567-04-06_01-14-29_AM_jpg.rf.c83950f096e7f3b94ace8300010d1396.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0704_JPG.rf.9eaec7318de533caa428aa198b848bb1.jpg: 640x640 1 person, 180.2ms\n",
      "Speed: 0.7ms preprocess, 180.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-690-_jpg.rf.614f5013e81edb6459786a2852721eef.jpg: 640x640 (no detections), 179.9ms\n",
      "Speed: 0.6ms preprocess, 179.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è posture-690-_jpg.rf.614f5013e81edb6459786a2852721eef.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-224-_jpg.rf.f75c1ab0018c69fcfded1c2cad12b2b5.jpg: 640x640 1 person, 187.5ms\n",
      "Speed: 0.8ms preprocess, 187.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-240-_jpg.rf.1f0613481a13fe7b30506ea4d09861f2.jpg: 640x640 1 person, 180.0ms\n",
      "Speed: 0.6ms preprocess, 180.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1719526099410735_jpg.rf.01f98659b37d4d4e207620d91c470645.jpg: 640x640 (no detections), 173.3ms\n",
      "Speed: 0.7ms preprocess, 173.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 1719526099410735_jpg.rf.01f98659b37d4d4e207620d91c470645.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0619_JPG.rf.d756197180b70390fc8a1605804a37f9.jpg: 640x640 1 person, 174.1ms\n",
      "Speed: 0.6ms preprocess, 174.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/4_jpg.rf.a20256939176819c705a80ecc2e4b93e.jpg: 640x640 1 person, 185.4ms\n",
      "Speed: 0.6ms preprocess, 185.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-310-_jpg.rf.bccbf40c53992e797ddf5fb3ca1f25f9.jpg: 640x640 1 person, 203.1ms\n",
      "Speed: 0.7ms preprocess, 203.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit121_jpg.rf.86ff8a2fe813e7d0071b96cf017bf834.jpg: 640x640 1 person, 182.9ms\n",
      "Speed: 0.7ms preprocess, 182.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/20230414194309_jpg.rf.87980bfca5c4b7311ef186335ecbb2fd.jpg: 640x640 1 person, 183.1ms\n",
      "Speed: 0.6ms preprocess, 183.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit1_jpg.rf.41100d5b417e67f24a2a015229ec8580.jpg: 640x640 1 person, 192.9ms\n",
      "Speed: 0.9ms preprocess, 192.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-104906_jpg.rf.ea411a304797c32cfd882d9ee0df477f.jpg: 640x640 1 person, 171.4ms\n",
      "Speed: 0.7ms preprocess, 171.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/9_webp.rf.7a6bd858e6f08e1c200785aa0fdd4914.jpg: 640x640 1 person, 170.1ms\n",
      "Speed: 0.7ms preprocess, 170.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 9_webp.rf.7a6bd858e6f08e1c200785aa0fdd4914.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/train01_png_jpg.rf.671042758921d2abaa3d76ea6c71555d.jpg: 640x640 4 persons, 166.5ms\n",
      "Speed: 0.6ms preprocess, 166.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe62_jpg.rf.c67124d9ced1cb6e600238b183671943.jpg: 640x640 2 persons, 166.0ms\n",
      "Speed: 0.8ms preprocess, 166.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/32_jpg.rf.a1486b4afe30483e58b22d80ea0f6f4c.jpg: 640x640 1 person, 167.0ms\n",
      "Speed: 0.7ms preprocess, 167.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-from-2022-07-18-00-38-38_jpg.rf.7275121950f3dcdf4756985039022e95.jpg: 640x640 1 person, 190.7ms\n",
      "Speed: 0.6ms preprocess, 190.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0679_JPG.rf.e071d78c88eb118a0e56f297fcde2e8a.jpg: 640x640 1 person, 165.5ms\n",
      "Speed: 0.6ms preprocess, 165.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-282-_jpg.rf.f904afd9f9a1149c06b8abe11b159e9b.jpg: 640x640 2 persons, 167.1ms\n",
      "Speed: 0.7ms preprocess, 167.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è Sitting-282-_jpg.rf.f904afd9f9a1149c06b8abe11b159e9b.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "‚ö†Ô∏è Sitting-282-_jpg.rf.f904afd9f9a1149c06b8abe11b159e9b.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/bad_posture_20241021_143705_png.rf.e27f3d8764d208ee0341203f487e0749.jpg: 640x640 1 person, 161.3ms\n",
      "Speed: 0.7ms preprocess, 161.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-498-_jpg.rf.ff264cd17ce42f5772d38f86dd5de1e3.jpg: 640x640 2 persons, 163.5ms\n",
      "Speed: 0.6ms preprocess, 163.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit51_jpg.rf.4b9a2d6d73685847dc64603ec7c17c70.jpg: 640x640 1 person, 164.0ms\n",
      "Speed: 0.7ms preprocess, 164.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è sit51_jpg.rf.4b9a2d6d73685847dc64603ec7c17c70.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-38-_jpg.rf.6eeb305a1a3d2c8d50f62c0437c16a29.jpg: 640x640 4 persons, 162.5ms\n",
      "Speed: 0.7ms preprocess, 162.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è Sitting-38-_jpg.rf.6eeb305a1a3d2c8d50f62c0437c16a29.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "‚ö†Ô∏è Sitting-38-_jpg.rf.6eeb305a1a3d2c8d50f62c0437c16a29.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pc80_jpg.rf.8b6460e8ee3723eb5c98d39ece2a3f46.jpg: 640x640 1 person, 164.1ms\n",
      "Speed: 0.6ms preprocess, 164.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1000_F_875541958_eHWQV8seWK9BwaFNWjZvZd1w0aAjMmXe_jpg.rf.8d5e7f95ae8ae8218a32d84732cd4a75.jpg: 640x640 1 person, 163.1ms\n",
      "Speed: 0.6ms preprocess, 163.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 1000_F_875541958_eHWQV8seWK9BwaFNWjZvZd1w0aAjMmXe_jpg.rf.8d5e7f95ae8ae8218a32d84732cd4a75.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9870_jpg.rf.5f70a62389a8c270cac7a91f01a1690c.jpg: 640x640 1 person, 161.2ms\n",
      "Speed: 0.7ms preprocess, 161.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/bad_posture_20241012_173243_png.rf.3e6a4e0f80dbcb11e23fa4b8ecf0c818.jpg: 640x640 1 person, 169.0ms\n",
      "Speed: 0.7ms preprocess, 169.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-104508_jpg.rf.1009c2c11dba14cf9cc68d25e8e51e20.jpg: 640x640 1 person, 168.3ms\n",
      "Speed: 0.6ms preprocess, 168.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/20230415093358_jpg.rf.a8581c63c4271780cdf0ea131e5e23a7.jpg: 640x640 3 persons, 163.2ms\n",
      "Speed: 0.6ms preprocess, 163.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 20230415093358_jpg.rf.a8581c63c4271780cdf0ea131e5e23a7.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-355-_jpg.rf.b7c4c3245b1f5a426e7ebe13b98ac4a3.jpg: 640x640 2 persons, 163.7ms\n",
      "Speed: 0.7ms preprocess, 163.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-980-_jpg.rf.b6b0b79d0009eb66a4c3151f968f39c4.jpg: 640x640 1 person, 161.1ms\n",
      "Speed: 0.6ms preprocess, 161.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-261-_jpg.rf.32d367e602c7189e17e8f9ef742adcbe.jpg: 640x640 2 persons, 165.7ms\n",
      "Speed: 0.6ms preprocess, 165.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è Sitting-261-_jpg.rf.32d367e602c7189e17e8f9ef742adcbe.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe45_jpg.rf.9cc69cef14fc365e5bf167f8f832f8c8.jpg: 640x640 3 persons, 161.3ms\n",
      "Speed: 0.6ms preprocess, 161.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0025_jpg.rf.5e5f4af8b597236c19c223fda5b0f576.jpg: 640x640 1 person, 166.1ms\n",
      "Speed: 0.6ms preprocess, 166.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-935-_jpg.rf.f49cd06ef976c626c174923c790f2bd2.jpg: 640x640 1 person, 165.6ms\n",
      "Speed: 0.7ms preprocess, 165.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/train03_png.rf.cd7a9a75e087a4aa4039c49b05f5a7cb.jpg: 640x384 1 person, 111.7ms\n",
      "Speed: 0.5ms preprocess, 111.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0643_JPG.rf.a4333e155fc8be40ba35e8b9215bbcab.jpg: 640x640 1 person, 167.1ms\n",
      "Speed: 0.7ms preprocess, 167.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Standing-119-_jpg.rf.057db26a8df4cab6546d1d3b0c994470.jpg: 640x640 4 persons, 162.0ms\n",
      "Speed: 0.6ms preprocess, 162.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/36_jpg.rf.f103436b46508e2d21eca46daf1e750b.jpg: 640x640 1 person, 167.8ms\n",
      "Speed: 0.5ms preprocess, 167.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0015_jpg.rf.be8ee2d49a8cbe62d11e42f009799da2.jpg: 640x640 1 person, 165.1ms\n",
      "Speed: 0.6ms preprocess, 165.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/56_jpg.rf.bf0252543b2127b55dab511aeaf14d8b.jpg: 640x640 1 person, 165.3ms\n",
      "Speed: 0.7ms preprocess, 165.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-471-_jpg.rf.38ac4052c37c1c2375adbd18fed47013.jpg: 640x640 1 person, 165.5ms\n",
      "Speed: 0.6ms preprocess, 165.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-900-_jpg.rf.fc57a953fb6e41a0437c539fb7a10201.jpg: 640x640 2 persons, 172.5ms\n",
      "Speed: 0.6ms preprocess, 172.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sr-massive-health-dangers-minimize-770x442_jpg.rf.103c536cc8e1a06374a5a008ae11c293.jpg: 384x640 1 person, 108.8ms\n",
      "Speed: 0.4ms preprocess, 108.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-627-_jpg.rf.b2eff8d9bb265538747ed1d84e355925.jpg: 640x640 1 person, 187.8ms\n",
      "Speed: 0.6ms preprocess, 187.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-934-_jpg.rf.337cb6503cc3d8a9930e53011212becd.jpg: 640x640 1 person, 170.8ms\n",
      "Speed: 0.7ms preprocess, 170.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-190-_jpg.rf.90461393e9274e6610a4b666685ed552.jpg: 640x640 1 person, 165.0ms\n",
      "Speed: 0.7ms preprocess, 165.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-315-_jpg.rf.492fab759fc9dec3c7700450a0eb00f8.jpg: 640x640 1 person, 163.1ms\n",
      "Speed: 0.7ms preprocess, 163.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-351-_jpg.rf.e463136f74dd81c7359da7b81916ef0f.jpg: 640x640 1 person, 165.2ms\n",
      "Speed: 0.7ms preprocess, 165.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0122_jpg.rf.38d11eaed6a1cd483dd103e0acfa0f70.jpg: 640x640 2 persons, 180.3ms\n",
      "Speed: 0.5ms preprocess, 180.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-39-_jpg.rf.a5b1f44b27c4fc7f91cc93552cae08bb.jpg: 640x640 1 person, 173.6ms\n",
      "Speed: 0.6ms preprocess, 173.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Pic-2020-Sep-11-1-26ee7bc6dc178a4de7fa45e964e6bf84_jpg.rf.1bdf0c00a20f42dc17c97f41586d5d43.jpg: 640x640 1 person, 165.6ms\n",
      "Speed: 0.7ms preprocess, 165.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0615_JPG.rf.6a1f773eee1eb769e82a5a2316517d6c.jpg: 640x640 1 person, 176.5ms\n",
      "Speed: 0.7ms preprocess, 176.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/bad_posture_20241021_142713_png.rf.4e078790cc1659dcf7958f60e952faa3.jpg: 640x640 1 person, 172.1ms\n",
      "Speed: 0.7ms preprocess, 172.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-586-_jpg.rf.3c41b1820c829ca42d80ffb445d2d61e.jpg: 640x640 1 person, 173.2ms\n",
      "Speed: 0.7ms preprocess, 173.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/16_jpg.rf.f6ebf36fcd24c0209bf550ceef9d00ed.jpg: 640x640 1 person, 173.5ms\n",
      "Speed: 0.6ms preprocess, 173.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0010_jpg.rf.17b04744bf1a29778823889eff446d2c.jpg: 640x640 2 persons, 173.4ms\n",
      "Speed: 0.7ms preprocess, 173.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9856_jpg.rf.ac4002a6b6fa0091c8484e200de659d3.jpg: 640x640 1 person, 171.1ms\n",
      "Speed: 0.6ms preprocess, 171.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9865_jpg.rf.b9be2434802eb53a81a7292113ff33a8.jpg: 640x480 1 person, 129.6ms\n",
      "Speed: 0.5ms preprocess, 129.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit8_jpg.rf.490028a7fdee66f87b2123eca7fe4235.jpg: 640x640 1 person, 173.2ms\n",
      "Speed: 0.8ms preprocess, 173.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/5dc9b425fd85fd145de9153c_girl-sitting-in-chair_jpg.rf.eef97515b524b76d860018daef774396.jpg: 640x640 1 person, 173.4ms\n",
      "Speed: 0.7ms preprocess, 173.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 5dc9b425fd85fd145de9153c_girl-sitting-in-chair_jpg.rf.eef97515b524b76d860018daef774396.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe12_jpg.rf.60d47c312337deffd04a6c936cd340aa.jpg: 640x640 1 person, 169.7ms\n",
      "Speed: 0.7ms preprocess, 169.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Standing-122-_jpg.rf.ff2a5733984d3fc893e770cea4609f26.jpg: 640x640 4 persons, 172.7ms\n",
      "Speed: 0.7ms preprocess, 172.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-700-_jpg.rf.bf3a33a2a52a887e015a4b2e62893b14.jpg: 640x640 1 person, 169.7ms\n",
      "Speed: 0.6ms preprocess, 169.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-561-_jpg.rf.e3157118bd24bed0bb4808e24bafc9a3.jpg: 640x640 1 person, 167.8ms\n",
      "Speed: 0.7ms preprocess, 167.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-192-_jpg.rf.69e920549b6025e3422799dfd7fc73e8.jpg: 640x640 1 person, 172.6ms\n",
      "Speed: 0.7ms preprocess, 172.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0662_JPG.rf.d8a6f210309d10b4d6ba70fddb061f38.jpg: 640x640 1 person, 166.0ms\n",
      "Speed: 0.6ms preprocess, 166.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0521_JPG.rf.2c4695a0eaf60ce4e716401a08c0c133.jpg: 640x640 1 person, 162.8ms\n",
      "Speed: 0.6ms preprocess, 162.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0120_jpg.rf.3b1dd6141a5919fdd98a08016b8c8af1.jpg: 640x640 2 persons, 181.8ms\n",
      "Speed: 0.7ms preprocess, 181.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit32_jpg.rf.961e78397ae54b50fafbba7ee3b375bf.jpg: 640x640 1 person, 184.1ms\n",
      "Speed: 0.6ms preprocess, 184.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-759-_jpg.rf.753c584c26a4b22c057f90d9b8ab398d.jpg: 640x640 2 persons, 173.8ms\n",
      "Speed: 0.7ms preprocess, 173.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/4_jpg.rf.6a072294a4ce8a0f4ceef7d0e82b69bd.jpg: 640x640 2 persons, 169.8ms\n",
      "Speed: 0.7ms preprocess, 169.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/images-2-_jpg.rf.1ec824247b8bb7cd8be289bb85962090.jpg: 640x640 2 persons, 168.6ms\n",
      "Speed: 0.7ms preprocess, 168.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-582-_jpg.rf.e58d93ce34985e3211a060792011e622.jpg: 640x640 1 person, 166.6ms\n",
      "Speed: 0.6ms preprocess, 166.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17195253703088033_jpg.rf.1b40899c12cac9916062a0725b82eae4.jpg: 640x640 (no detections), 172.1ms\n",
      "Speed: 0.6ms preprocess, 172.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 17195253703088033_jpg.rf.1b40899c12cac9916062a0725b82eae4.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/20230415093340_jpg.rf.585c9922f8741a5e8173514e2f380687.jpg: 640x640 1 person, 178.2ms\n",
      "Speed: 0.8ms preprocess, 178.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/bad_posture_20241021_143020_png.rf.28517057a69de344679f88cd283601b3.jpg: 640x640 1 person, 175.2ms\n",
      "Speed: 0.6ms preprocess, 175.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit82_jpg.rf.fab57c696a58089cf512d4ab1570ac8d.jpg: 640x640 1 person, 173.8ms\n",
      "Speed: 0.6ms preprocess, 173.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0021_jpg.rf.51219822d482ed97b0afef6ba0a4680a.jpg: 640x640 2 persons, 180.2ms\n",
      "Speed: 0.7ms preprocess, 180.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/bad_posture_20241012_172807_png.rf.042c27647206e093c506848b9954944b.jpg: 640x640 1 person, 173.8ms\n",
      "Speed: 0.6ms preprocess, 173.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/LINE_ALBUM_202452_240502_27_jpg.rf.703f24621a7d7ccb81f5cb65535a072c.jpg: 640x640 1 person, 177.7ms\n",
      "Speed: 0.8ms preprocess, 177.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/val03_png_jpg.rf.26f72f5630a301043fcb5ab6c962a5a4.jpg: 640x640 2 persons, 177.1ms\n",
      "Speed: 0.6ms preprocess, 177.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-256-_jpg.rf.240976ad55ab336726806175c760b8b8.jpg: 640x640 1 person, 173.8ms\n",
      "Speed: 0.9ms preprocess, 173.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/good_posture_20241021_142159_png.rf.1d65d469bac34cbb265b4def9ec623d2.jpg: 640x640 1 person, 200.7ms\n",
      "Speed: 0.6ms preprocess, 200.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-901-_jpg.rf.2939ff42a13187a685768497ca4f2937.jpg: 640x640 1 person, 175.8ms\n",
      "Speed: 0.8ms preprocess, 175.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1000_F_165902124_gL0PcxZaYrWrqVSP32iHNzWKWgUIpYvL_jpg.rf.2d324159898968631c6673c98481889d.jpg: 640x640 1 person, 174.4ms\n",
      "Speed: 0.6ms preprocess, 174.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-168-_jpg.rf.f7e1de209101f9f6c6cb5881606cf84b.jpg: 640x640 1 person, 177.5ms\n",
      "Speed: 0.6ms preprocess, 177.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1000_F_482623992_lrAI9H5tHoulnk1zZvRuakmBtWrENtZq_jpg.rf.698ef9c678819720ec8d6e76f98b433e.jpg: 640x640 1 person, 179.4ms\n",
      "Speed: 0.6ms preprocess, 179.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/12_jpg.rf.036c647e47b1c0562e9a454b171235c8.jpg: 640x640 1 person, 173.2ms\n",
      "Speed: 0.7ms preprocess, 173.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-659-_jpg.rf.780be671a5820aeaf85d8953048a6ff3.jpg: 640x640 1 person, 178.8ms\n",
      "Speed: 0.7ms preprocess, 178.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-104219_jpg.rf.6c3d16b36a09ecf69a899bcb399ba774.jpg: 640x640 1 person, 174.7ms\n",
      "Speed: 0.7ms preprocess, 174.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-566-_jpg.rf.a13d3bbae0ecf6c08e3b1934ce1cc922.jpg: 640x640 1 person, 181.3ms\n",
      "Speed: 0.7ms preprocess, 181.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/train02_png_jpg.rf.705f7cff850c5535b787224e6158689f.jpg: 640x640 1 person, 172.5ms\n",
      "Speed: 0.6ms preprocess, 172.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/good_posture_20241021_141536_png.rf.cfa7c5e5f9dd524d92b3ece26e0308b9.jpg: 640x640 1 person, 172.8ms\n",
      "Speed: 0.6ms preprocess, 172.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è good_posture_20241021_141536_png.rf.cfa7c5e5f9dd524d92b3ece26e0308b9.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/sit119_jpg.rf.ab1861f6062c0f1bbc11aa569e1911d0.jpg: 640x640 2 persons, 173.7ms\n",
      "Speed: 0.6ms preprocess, 173.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-142-_jpg.rf.e2ebb1eadf0c0f5c4dab668292564a3d.jpg: 640x640 1 person, 170.5ms\n",
      "Speed: 0.7ms preprocess, 170.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/00085_png_jpg.rf.d346fbd1f714a5357d9943ee4ffcd807.jpg: 640x640 1 person, 171.4ms\n",
      "Speed: 0.6ms preprocess, 171.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/back-b-1-1-400x600xc_jpg.rf.2be9cee22852d3ae63dd342910cd8bb9.jpg: 640x640 4 persons, 173.2ms\n",
      "Speed: 0.6ms preprocess, 173.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è back-b-1-1-400x600xc_jpg.rf.2be9cee22852d3ae63dd342910cd8bb9.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-1003-_jpg.rf.8823061f1cd02df900d4e4e0281d02f3.jpg: 640x640 1 person, 168.3ms\n",
      "Speed: 1.0ms preprocess, 168.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1719525376493811_jpg.rf.3c3db6fdbbc82b40205573cee52b632b.jpg: 640x640 (no detections), 176.3ms\n",
      "Speed: 0.8ms preprocess, 176.3ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 1719525376493811_jpg.rf.3c3db6fdbbc82b40205573cee52b632b.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-104955_jpg.rf.b2c5e4d1c93d3ed62c7779ef719b834a.jpg: 640x640 1 person, 178.3ms\n",
      "Speed: 0.7ms preprocess, 178.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17195261001191518_jpg.rf.bebc19827da2d67e06f0bcd9f2f31078.jpg: 640x640 1 person, 182.4ms\n",
      "Speed: 0.6ms preprocess, 182.4ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-637-_jpg.rf.8842bbd2f4dde4f9c247abb54fb54733.jpg: 640x640 1 person, 177.9ms\n",
      "Speed: 0.9ms preprocess, 177.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1000_F_482623992_lrAI9H5tHoulnk1zZvRuakmBtWrENtZq_jpg.rf.3c552aa5cf1d904ced8a6ae36662faa5.jpg: 640x640 1 person, 176.4ms\n",
      "Speed: 0.7ms preprocess, 176.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/00078_png_jpg.rf.6cee7c8d1bf5b329e47ee16724a6fc01.jpg: 640x640 1 person, 176.3ms\n",
      "Speed: 0.7ms preprocess, 176.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Screenshot-2022-08-09-104718_jpg.rf.42dca23c314c464d67dc3624e5cc69f7.jpg: 640x640 1 person, 172.5ms\n",
      "Speed: 0.7ms preprocess, 172.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/images-5-_JPG_jpg.rf.47e15faef9ae87778b71d9561a05e069.jpg: 640x640 1 person, 179.6ms\n",
      "Speed: 0.6ms preprocess, 179.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-430-_jpg.rf.e416ae6b2e43d3b04ef79e25355b32b2.jpg: 640x640 1 person, 178.2ms\n",
      "Speed: 0.6ms preprocess, 178.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-80-_jpg.rf.72f25994c5cd099fae52e33450d492e3.jpg: 640x640 1 person, 175.5ms\n",
      "Speed: 0.7ms preprocess, 175.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0012_jpg.rf.545534252e384f0b8e3932279bf8d1c8.jpg: 640x640 1 person, 174.7ms\n",
      "Speed: 0.7ms preprocess, 174.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-342-_jpg.rf.2b79d63f2aa91edb8d0d0f8f870bcbae.jpg: 640x640 8 persons, 195.1ms\n",
      "Speed: 0.7ms preprocess, 195.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è Sitting-342-_jpg.rf.2b79d63f2aa91edb8d0d0f8f870bcbae.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0686_JPG.rf.c9a2e987c043b44f13643412dff8df08.jpg: 640x640 1 person, 174.5ms\n",
      "Speed: 0.7ms preprocess, 174.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-962-_jpg.rf.d4768011f58fdd688f452ee070a58d2c.jpg: 640x640 2 persons, 174.5ms\n",
      "Speed: 0.7ms preprocess, 174.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Ban-Hoc-Chong-Gu_jpg.rf.d0ecdce7e8d6c1007a529fcec8ec2d95.jpg: 640x640 1 person, 169.2ms\n",
      "Speed: 0.6ms preprocess, 169.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è Ban-Hoc-Chong-Gu_jpg.rf.d0ecdce7e8d6c1007a529fcec8ec2d95.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0543_JPG.rf.915fbb0bc8dc2688da9ee50a7c324836.jpg: 640x640 1 person, 174.6ms\n",
      "Speed: 0.7ms preprocess, 174.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_9403-1-768x1024_jpg.rf.e404370c37b0a4d3df5f814f302e4728.jpg: 640x640 2 persons, 178.1ms\n",
      "Speed: 0.7ms preprocess, 178.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è IMG_9403-1-768x1024_jpg.rf.e404370c37b0a4d3df5f814f302e4728.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-84-_jpg.rf.96d60e6f6e28b26bbb53f37fc407363b.jpg: 640x640 1 person, 175.5ms\n",
      "Speed: 0.8ms preprocess, 175.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-83-_jpg.rf.d499198b49b6542cff7b368d46a8588b.jpg: 640x640 1 person, 173.8ms\n",
      "Speed: 0.7ms preprocess, 173.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/val06_png_jpg.rf.b7adcc7eaa2444d9787b8c3d97163795.jpg: 640x640 1 person, 174.5ms\n",
      "Speed: 0.7ms preprocess, 174.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/images-4-_jpg.rf.039f17196ef0233b09126cac22cc0526.jpg: 640x640 2 persons, 175.6ms\n",
      "Speed: 0.6ms preprocess, 175.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è images-4-_jpg.rf.039f17196ef0233b09126cac22cc0526.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0549_JPG.rf.043d65bbde018af957e06ed24023a675.jpg: 640x640 1 person, 174.6ms\n",
      "Speed: 0.8ms preprocess, 174.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-42-_jpg.rf.29233dcaffaec8c7705a7639bc7edb70.jpg: 640x640 1 person, 205.2ms\n",
      "Speed: 0.6ms preprocess, 205.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe42_jpg.rf.7ce7082d323633783fdebda430006581.jpg: 640x640 1 person, 175.8ms\n",
      "Speed: 0.7ms preprocess, 175.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-381-_jpg.rf.8fd12385e53396399a2fcff776d6337a.jpg: 640x640 4 persons, 178.3ms\n",
      "Speed: 0.6ms preprocess, 178.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è posture-381-_jpg.rf.8fd12385e53396399a2fcff776d6337a.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/train05_png.rf.6facba8dd084ccbe0c7a15781040d419.jpg: 640x416 1 person, 124.1ms\n",
      "Speed: 0.5ms preprocess, 124.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 416)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1000_F_481874393_17sfHiszMLv1wyEOVDc1JDmTuWEGSUHr_jpg.rf.e358c06ffe072adfa63878107c784fca.jpg: 640x640 1 person, 187.6ms\n",
      "Speed: 0.6ms preprocess, 187.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/LINE_ALBUM_202452_240502_51_jpg.rf.7fcb829a701269f3cb5e31ef944db76e.jpg: 640x640 1 person, 179.7ms\n",
      "Speed: 0.6ms preprocess, 179.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/1000_F_892991100_vZLOkPqTNOA2QX5SeJbsimhjbAuwcShr_jpg.rf.1226166ccbcc46f3ad84dfbe3b0f18f4.jpg: 640x640 1 person, 175.0ms\n",
      "Speed: 0.6ms preprocess, 175.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/42_jpg.rf.86e417db33c948954e7532aeadebf5a0.jpg: 640x640 1 person, 179.3ms\n",
      "Speed: 0.7ms preprocess, 179.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-924-_jpg.rf.c594238af6e66342bf3809fec26fc934.jpg: 640x640 1 person, 176.1ms\n",
      "Speed: 0.6ms preprocess, 176.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/IMG_E0558_JPG.rf.56e1dc353a99ad3a84cbb80efa3b057c.jpg: 640x640 1 person, 170.9ms\n",
      "Speed: 0.6ms preprocess, 170.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/Sitting-244-_jpg.rf.3cc742716931fa50bd4ef2fba24706a2.jpg: 640x640 3 persons, 176.8ms\n",
      "Speed: 0.6ms preprocess, 176.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-548-_jpg.rf.0ac2cad5cf10052867645c3347f8c142.jpg: 640x640 1 person, 176.8ms\n",
      "Speed: 0.7ms preprocess, 176.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/60_png.rf.a9775b9b38a9555c03581bf10f89893e.jpg: 640x640 1 person, 180.0ms\n",
      "Speed: 0.7ms preprocess, 180.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 60_png.rf.a9775b9b38a9555c03581bf10f89893e.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/83_png.rf.bf5d22f5dd7a9b7630d904c9af4d23c5.jpg: 640x640 1 person, 214.0ms\n",
      "Speed: 0.8ms preprocess, 214.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 83_png.rf.bf5d22f5dd7a9b7630d904c9af4d23c5.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/pe46_jpg.rf.63d978e52e95f92c6f26069c4f2e831e.jpg: 640x640 3 persons, 229.1ms\n",
      "Speed: 0.8ms preprocess, 229.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/20240711_205342_jpg.rf.6e447eba25f4896df9204ba3334aa7eb.jpg: 640x640 1 person, 193.3ms\n",
      "Speed: 0.7ms preprocess, 193.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-485-_jpg.rf.4963467afc37f5ff9f249ad2b6d20497.jpg: 640x640 (no detections), 210.8ms\n",
      "Speed: 0.6ms preprocess, 210.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è posture-485-_jpg.rf.4963467afc37f5ff9f249ad2b6d20497.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/bad_posture_20241021_142418_png.rf.97c853302792b1544584ec3615031121.jpg: 640x640 1 person, 177.9ms\n",
      "Speed: 0.6ms preprocess, 177.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/LINE_ALBUM_202452_240502_29_jpg.rf.156d8d78e48ee7e998d6cba06ddb315c.jpg: 640x640 1 person, 200.4ms\n",
      "Speed: 0.6ms preprocess, 200.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/posture-698-_jpg.rf.c18cc318f02a65ca684c20de904e03d1.jpg: 640x640 1 person, 228.7ms\n",
      "Speed: 1.0ms preprocess, 228.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/17195253726924543_jpg.rf.ef4577c71d741ebefdc069c3cb9a5f56.jpg: 640x640 (no detections), 185.2ms\n",
      "Speed: 0.7ms preprocess, 185.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è 17195253726924543_jpg.rf.ef4577c71d741ebefdc069c3cb9a5f56.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/20230415091732_jpg.rf.a30e0fc488a1f236154db3c9dc305964.jpg: 640x640 2 persons, 178.0ms\n",
      "Speed: 0.7ms preprocess, 178.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/0045_jpg.rf.2c2daaca5b0109c945457ef9ebee0e1e.jpg: 640x640 1 person, 183.7ms\n",
      "Speed: 0.6ms preprocess, 183.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /Users/parkseongho/visualstudio-workspace/python-project/roboflowfin/train/images/good_posture_20241021_141341_png.rf.0cf106381a08725a0d20ef5af368a6ab.jpg: 640x640 1 person, 178.7ms\n",
      "Speed: 0.6ms preprocess, 178.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "‚ö†Ô∏è good_posture_20241021_141341_png.rf.0cf106381a08725a0d20ef5af368a6ab.jpgÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU 0.5 ÎØ∏Îßå\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 108\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Ïã§Ìñâ\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m--> 108\u001b[0m     \u001b[43mprocess_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 61\u001b[0m, in \u001b[0;36mprocess_folder\u001b[0;34m(split_name, base_path, iou_threshold)\u001b[0m\n\u001b[1;32m     58\u001b[0m image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_dir, image_file)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# YOLOv8 Pose Ï∂îÎ°†\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m pred_boxes \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mxywhn\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mtolist()  \u001b[38;5;66;03m# ÏòàÏ∏° bbox\u001b[39;00m\n\u001b[1;32m     63\u001b[0m keypoints_list \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeypoints\u001b[38;5;241m.\u001b[39mxyn\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/ultralytics/engine/model.py:185\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    158\u001b[0m     source: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mint\u001b[39m, Image\u001b[38;5;241m.\u001b[39mImage, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    159\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    161\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/ultralytics/engine/model.py:555\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[0;32m--> 555\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/ultralytics/engine/predictor.py:227\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/torch/utils/_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/ultralytics/engine/predictor.py:330\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 330\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/ultralytics/engine/predictor.py:182\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[0;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m    177\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    178\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    181\u001b[0m )\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/ultralytics/nn/autobackend.py:636\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[0;34m(self, im, augment, visualize, embed, **kwargs)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[0;32m--> 636\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/ultralytics/nn/tasks.py:138\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/ultralytics/nn/tasks.py:156\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/ultralytics/nn/tasks.py:179\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 179\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m    180\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/ultralytics/nn/modules/block.py:318\u001b[0m, in \u001b[0;36mC2f.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[1;32m    317\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 318\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/ultralytics/nn/modules/block.py:318\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[1;32m    317\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 318\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/ultralytics/nn/modules/block.py:495\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    494\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply bottleneck with optional shortcut connection.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/ultralytics/nn/modules/conv.py:92\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     83\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    Apply convolution and activation without batch normalization.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/tf-metal/lib/python3.10/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# YOLO Î™®Îç∏ Î°úÎìú\n",
    "model = YOLO(\"yolov8m-pose.pt\")  # ÏÇ¨Ï†Ñ ÌïôÏäµÎêú Ìè¨Ï¶à Î™®Îç∏\n",
    "\n",
    "def iou(box1, box2):\n",
    "    \"\"\" box: [x_center, y_center, w, h], Ï†ïÍ∑úÌôîÎêú Ï¢åÌëú Í∏∞Ï§Ä IOU \"\"\"\n",
    "    x1_min = box1[0] - box1[2]/2\n",
    "    y1_min = box1[1] - box1[3]/2\n",
    "    x1_max = box1[0] + box1[2]/2\n",
    "    y1_max = box1[1] + box1[3]/2\n",
    "\n",
    "    x2_min = box2[0] - box2[2]/2\n",
    "    y2_min = box2[1] - box2[3]/2\n",
    "    x2_max = box2[0] + box2[2]/2\n",
    "    y2_max = box2[1] + box2[3]/2\n",
    "\n",
    "    inter_xmin = max(x1_min, x2_min)\n",
    "    inter_ymin = max(y1_min, y2_min)\n",
    "    inter_xmax = min(x1_max, x2_max)\n",
    "    inter_ymax = min(y1_max, y2_max)\n",
    "\n",
    "    inter_w = max(0, inter_xmax - inter_xmin)\n",
    "    inter_h = max(0, inter_ymax - inter_ymin)\n",
    "    inter_area = inter_w * inter_h\n",
    "\n",
    "    area1 = (x1_max - x1_min) * (y1_max - y1_min)\n",
    "    area2 = (x2_max - x2_min) * (y2_max - y2_min)\n",
    "    union_area = area1 + area2 - inter_area\n",
    "\n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "def process_folder(split_name, base_path=\"roboflowfin\", iou_threshold=0.5):\n",
    "    label_dir = os.path.join(base_path, split_name, 'labels')\n",
    "    image_dir = os.path.join(base_path, split_name, 'images')\n",
    "    output_rows = []\n",
    "\n",
    "    for label_file in os.listdir(label_dir):\n",
    "        if not label_file.endswith(\".txt\"):\n",
    "            continue\n",
    "\n",
    "        # Ïù¥ÎØ∏ÏßÄ ÌôïÏû•Ïûê ÎèôÏ†Å Ï≤òÎ¶¨\n",
    "        image_file = None\n",
    "        for ext in [\".jpg\", \".png\"]:\n",
    "            potential_image = label_file.replace(\".txt\", ext)\n",
    "            if os.path.exists(os.path.join(image_dir, potential_image)):\n",
    "                image_file = potential_image\n",
    "                break\n",
    "        if not image_file:\n",
    "            print(f\"‚ö†Ô∏è {label_file}Ïóê ÎåÄÏùëÌïòÎäî Ïù¥ÎØ∏ÏßÄ ÌååÏùº ÏóÜÏùå\")\n",
    "            continue\n",
    "\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "\n",
    "        # ÎùºÎ≤® ÌååÏùº ÏùΩÍ∏∞ Î∞è ÎπÑÏñ¥ ÏûàÎäîÏßÄ ÌôïÏù∏\n",
    "        label_path = os.path.join(label_dir, label_file)\n",
    "        with open(label_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            if not lines or all(line.strip() == \"\" for line in lines):  # ÎùºÎ≤® ÌååÏùºÏù¥ ÎπÑÏñ¥ ÏûàÎäî Í≤ΩÏö∞\n",
    "                print(f\"‚ö†Ô∏è {label_file} ÎùºÎ≤® ÌååÏùºÏù¥ ÎπÑÏñ¥ ÏûàÏùå, Í±¥ÎÑàÎúÄ\")\n",
    "                continue\n",
    "\n",
    "        # YOLOv8 Pose Ï∂îÎ°†\n",
    "        results = model(image_path)\n",
    "        pred_boxes = results[0].boxes.xywhn.cpu().tolist()  # ÏòàÏ∏° bbox\n",
    "        keypoints_list = results[0].keypoints.xyn.cpu().tolist()\n",
    "\n",
    "        # ÎùºÎ≤® ÌååÏùº Ï≤òÎ¶¨\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 5:  # ÎùºÎ≤® ÌòïÏãùÏù¥ ÏûòÎ™ªÎêú Í≤ΩÏö∞\n",
    "                print(f\"‚ö†Ô∏è {label_file}Ïùò ÎùºÎ≤® ÌòïÏãùÏù¥ ÏûòÎ™ªÎê®: {line.strip()}\")\n",
    "                continue\n",
    "            class_id = int(parts[0])  # ÌÅ¥ÎûòÏä§ ID Í∑∏ÎåÄÎ°ú ÏÇ¨Ïö©\n",
    "            bbox_gt = list(map(float, parts[1:5]))  # GT Î∞îÏö¥Îî©Î∞ïÏä§\n",
    "\n",
    "            # Í∞ÄÏû• ÎÜíÏùÄ IOUÎ•º Í∞ÄÏßÑ ÏòàÏ∏° Î∞ïÏä§ Ï∞æÍ∏∞\n",
    "            best_iou = 0\n",
    "            best_kps = None\n",
    "            for pred_box, kps in zip(pred_boxes, keypoints_list):\n",
    "                iou_val = iou(bbox_gt, pred_box)\n",
    "                if iou_val > best_iou and iou_val >= iou_threshold:\n",
    "                    best_iou = iou_val\n",
    "                    best_kps = kps\n",
    "\n",
    "            # ÌÇ§Ìè¨Ïù∏Ìä∏ Ï≤òÎ¶¨\n",
    "            if best_kps:\n",
    "                padded_kps = best_kps + [0.0] * (51 - len(best_kps))  # 17√ó3 = 51\n",
    "                row = [image_file, class_id] + bbox_gt + padded_kps  # class_id ÏÇ¨Ïö©\n",
    "                output_rows.append(row)\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è {image_file}ÏóêÏÑú keypoint Ï∂îÎ°† Ïã§Ìå® ÎòêÎäî IOU {iou_threshold} ÎØ∏Îßå\")\n",
    "\n",
    "    # ÌñâÏù¥ ÏóÜÏúºÎ©¥ Í±¥ÎÑàÎúÄ\n",
    "    if not output_rows:\n",
    "        print(f\"‚ùå {split_name}Ïóê Ïú†Ìö®Ìïú Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå\")\n",
    "        return\n",
    "\n",
    "    # Ïª¨Îüº Íµ¨ÏÑ±\n",
    "    expected_len = len(output_rows[0])\n",
    "    columns = ['filename', 'class_id', 'x_center', 'y_center', 'width', 'height']\n",
    "    num_kps = expected_len - 6\n",
    "    for i in range(num_kps // 3):\n",
    "        columns += [f'kp{i}_x', f'kp{i}_y', f'kp{i}_v']\n",
    "\n",
    "    df = pd.DataFrame(output_rows, columns=columns)\n",
    "    df.to_csv(f\"{split_name}_pose_from_yolo.csv\", index=False)\n",
    "    print(f\"‚úÖ {split_name}_pose_from_yolo.csv Ï†ÄÏû• ÏôÑÎ£å ({len(df)} rows)\")\n",
    "\n",
    "# Ïã§Ìñâ\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    process_folder(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb09d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import ast\n",
    "\n",
    "# CSV Î°úÎìú\n",
    "df = pd.read_csv(\"train_pose_from_yolo.csv\")\n",
    "image_dir = \"roboflowfin/train/images\"\n",
    "\n",
    "# ÏãúÍ∞ÅÌôî Î£®ÌîÑ\n",
    "for idx, row in df.iterrows():\n",
    "    img_path = os.path.join(image_dir, row['filename'])\n",
    "    if not os.path.exists(img_path):\n",
    "        continue\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # Î∞îÏö¥Îî©Î∞ïÏä§ Í∑∏Î¶¨Í∏∞\n",
    "    x_center = row['x_center'] * w\n",
    "    y_center = row['y_center'] * h\n",
    "    box_width = row['width'] * w\n",
    "    box_height = row['height'] * h\n",
    "    x1 = int(x_center - box_width / 2)\n",
    "    y1 = int(y_center - box_height / 2)\n",
    "    x2 = int(x_center + box_width / 2)\n",
    "    y2 = int(y_center + box_height / 2)\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # ÌÇ§Ìè¨Ïù∏Ìä∏ Í∑∏Î¶¨Í∏∞\n",
    "    for i in range(17):  # 17 keypoints Í∏∞Ï§Ä\n",
    "        try:\n",
    "            point_str = row[f'kp{i}_x']  # Ïòà: \"[0.123, 0.456]\"\n",
    "            if isinstance(point_str, str):\n",
    "                x, y = ast.literal_eval(point_str)  # Î¨∏ÏûêÏó¥ ‚Üí [x, y]\n",
    "                x, y = float(x) * w, float(y) * h\n",
    "                if x > 0 and y > 0:\n",
    "                    cv2.circle(img, (int(x), int(y)), 4, (0, 0, 255), -1)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå keypoint {i} Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò: {e}\")\n",
    "\n",
    "    out_path = os.path.join(\"visualized\", row['filename'])\n",
    "    os.makedirs(\"visualized\", exist_ok=True)\n",
    "    cv2.imwrite(out_path, img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea6ae21",
   "metadata": {},
   "source": [
    "# ÌÇ§Ìè¨Ïù∏Ìä∏Î•º Î∞∞Ïó¥ÏóêÏÑú Í∫ºÎÇ¥ÏÑú ÌòïÏãùÏùÑ Î∞îÍøà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "effe0607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ÏÉà Íµ¨Ï°∞Ïùò CSV Ï†ÄÏû• ÏôÑÎ£å!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "df = pd.read_csv(\"valid_pose_from_yolo.csv\")\n",
    "\n",
    "# ÏÉàÎ°úÏö¥ Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ Íµ¨ÏÑ±\n",
    "new_rows = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    new_row = {\n",
    "        'filename': row['filename'],\n",
    "        'class_id': row['class_id'],\n",
    "        'x_center': row['x_center'],\n",
    "        'y_center': row['y_center'],\n",
    "        'width': row['width'],\n",
    "        'height': row['height'],\n",
    "    }\n",
    "\n",
    "    for i in range(17):\n",
    "        try:\n",
    "            value = row[f'kp{i}_x']\n",
    "            if isinstance(value, str):\n",
    "                xy = ast.literal_eval(value)  # \"[x, y]\" ‚Üí [x, y]\n",
    "            elif isinstance(value, float):  # Ïù¥ÎØ∏ floatÏù∏ Í≤ΩÏö∞ (Ïòà: 0.0)\n",
    "                xy = [0.0, 0.0]  # ÎàÑÎùΩÎêú keypointÎ°ú Í∞ÑÏ£º\n",
    "            else:\n",
    "                raise ValueError(\"Ïïå Ïàò ÏóÜÎäî ÌÉÄÏûÖ\")\n",
    "\n",
    "            new_row[f'kp{i}_x'] = xy[0]\n",
    "            new_row[f'kp{i}_y'] = xy[1]\n",
    "            new_row[f'kp{i}_v'] = 0.0 if xy == [0.0, 0.0] else 2.0\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è kp{i} ÌååÏã± Ïã§Ìå®: {e}\")\n",
    "            new_row[f'kp{i}_x'] = 0.0\n",
    "            new_row[f'kp{i}_y'] = 0.0\n",
    "            new_row[f'kp{i}_v'] = 0.0\n",
    "\n",
    "\n",
    "    new_rows.append(new_row)\n",
    "\n",
    "df_new = pd.DataFrame(new_rows)\n",
    "df_new.to_csv(\"valid_pose_parsed.csv\", index=False)\n",
    "print(\"‚úÖ ÏÉà Íµ¨Ï°∞Ïùò CSV Ï†ÄÏû• ÏôÑÎ£å!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d5c349",
   "metadata": {},
   "source": [
    "# Î∞îÏö¥Îî© Î∞ïÏä§ÏôÄ ÌÇ§Ìè¨Ïù∏Ìä∏Î•º Ïù¥ÎØ∏ÏßÄÏóê Í∑∏Î¶º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6c63f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# CSV Î°úÎìú\n",
    "df = pd.read_csv(\"train_pose_parsed.csv\")  # ÏÉà CSV ÌååÏùºÎ™ÖÏúºÎ°ú Î∞îÍøîÏ£ºÏÑ∏Ïöî\n",
    "image_dir = \"roboflowfin/train/images\"\n",
    "\n",
    "# ÏãúÍ∞ÅÌôî Î£®ÌîÑ\n",
    "for idx, row in df.iterrows():\n",
    "    img_path = os.path.join(image_dir, row['filename'])\n",
    "    if not os.path.exists(img_path):\n",
    "        continue\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    # h, w = img.shape[:2]\n",
    "\n",
    "    # # Î∞îÏö¥Îî©Î∞ïÏä§ Í∑∏Î¶¨Í∏∞\n",
    "    # x_center = row['x_center'] * w\n",
    "    # y_center = row['y_center'] * h\n",
    "    # box_width = row['width'] * w\n",
    "    # box_height = row['height'] * h\n",
    "    # x1 = int(x_center - box_width / 2)\n",
    "    # y1 = int(y_center - box_height / 2)\n",
    "    # x2 = int(x_center + box_width / 2)\n",
    "    # y2 = int(y_center + box_height / 2)\n",
    "    # cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # ÌÇ§Ìè¨Ïù∏Ìä∏ Í∑∏Î¶¨Í∏∞\n",
    "    for i in range(17):  # 17 keypoints\n",
    "        try:\n",
    "            x = float(row[f'kp{i}_x']) * w\n",
    "            y = float(row[f'kp{i}_y']) * h\n",
    "            v = float(row[f'kp{i}_v'])\n",
    "\n",
    "            if v >= 1:  # Î≥¥Ïù¥Îäî Ï†êÎßå Îπ®Í∞ÑÏÉâÏúºÎ°ú\n",
    "                cv2.circle(img, (int(x), int(y)), 4, (0, 0, 255), -1)\n",
    "            elif v == 0:\n",
    "                cv2.circle(img, (int(x), int(y)), 4, (128, 128, 128), -1)  # Ïïà Î≥¥Ïù¥Îäî Ï†êÏùÄ ÌöåÏÉâ\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è keypoint {i} Ï≤òÎ¶¨ Ïò§Î•ò: {e}\")\n",
    "\n",
    "    out_path = os.path.join(\"train-visualized\", row['filename'])\n",
    "    os.makedirs(\"train-visualized\", exist_ok=True)\n",
    "    cv2.imwrite(out_path, img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f2f4e3",
   "metadata": {},
   "source": [
    "# Ïä§ÏºàÎ†àÌÜ§ ÏãúÍ∞ÅÌôî"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f51ef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# CSV Î°úÎìú\n",
    "df = pd.read_csv(\"train_pose_parsed.csv\")\n",
    "image_dir = \"roboflowfin/train/images\"\n",
    "\n",
    "# COCO keypoint Ïó∞Í≤∞ Íµ¨Ï°∞\n",
    "skeleton = [\n",
    "    (5, 7), (7, 9),    # ÏôºÌåî\n",
    "    (6, 8), (8, 10),   # Ïò§Î•∏Ìåî\n",
    "    (11, 13), (13, 15),  # ÏôºÎã§Î¶¨\n",
    "    (12, 14), (14, 16),  # Ïò§Î•∏Îã§Î¶¨\n",
    "    (5, 6), (5, 11), (6, 12),  # Î™∏ÌÜµ\n",
    "    (0, 1), (1, 3), (0, 2), (2, 4)  # ÏñºÍµ¥\n",
    "]\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    img_path = os.path.join(image_dir, row['filename'])\n",
    "    if not os.path.exists(img_path):\n",
    "        continue\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # Î∞îÏö¥Îî© Î∞ïÏä§\n",
    "    x_center = row['x_center'] * w\n",
    "    y_center = row['y_center'] * h\n",
    "    box_width = row['width'] * w\n",
    "    box_height = row['height'] * h\n",
    "    x1 = int(x_center - box_width / 2)\n",
    "    y1 = int(y_center - box_height / 2)\n",
    "    x2 = int(x_center + box_width / 2)\n",
    "    y2 = int(y_center + box_height / 2)\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # keypoints Ï†ÄÏû• (ÎÇòÏ§ëÏóê skeletonÏö©)\n",
    "    keypoints = []\n",
    "\n",
    "    for i in range(17):\n",
    "        try:\n",
    "            x = float(row[f'kp{i}_x']) * w\n",
    "            y = float(row[f'kp{i}_y']) * h\n",
    "            v = float(row[f'kp{i}_v'])\n",
    "\n",
    "            keypoints.append((x, y, v))  # Ï†ÄÏû•\n",
    "\n",
    "            if v >= 1:\n",
    "                cv2.circle(img, (int(x), int(y)), 4, (0, 0, 255), -1)  # Î≥¥Ïù¥Îäî Ï†ê: Îπ®Í∞ÑÏÉâ\n",
    "            elif v == 0:\n",
    "                cv2.circle(img, (int(x), int(y)), 4, (128, 128, 128), -1)  # Ïïà Î≥¥Ïù¥Îäî Ï†ê: ÌöåÏÉâ\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è keypoint {i} Ïò§Î•ò: {e}\")\n",
    "            keypoints.append((0.0, 0.0, 0.0))\n",
    "\n",
    "    # Ïä§ÏºàÎ†àÌÜ§ ÏÑ† Í∑∏Î¶¨Í∏∞\n",
    "    for i, j in skeleton:\n",
    "        x1, y1, v1 = keypoints[i]\n",
    "        x2, y2, v2 = keypoints[j]   \n",
    "        if (x1 > 0 and y1 > 0) and (x2 > 0 and y2 > 0):\n",
    "            cv2.line(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 255), 2)  # ÎÖ∏ÎûÄÏÉâ ÏÑ†\n",
    "\n",
    "    out_path = os.path.join(\"skeleton-visualized\", row['filename'])\n",
    "    os.makedirs(\"skeleton-visualized\", exist_ok=True)\n",
    "    cv2.imwrite(out_path, img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PoseDetect-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
